{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T20:44:16.946176Z",
     "iopub.status.busy": "2022-05-17T20:44:16.945871Z",
     "iopub.status.idle": "2022-05-17T20:44:16.950335Z",
     "shell.execute_reply": "2022-05-17T20:44:16.949382Z",
     "shell.execute_reply.started": "2022-05-17T20:44:16.946147Z"
    }
   },
   "outputs": [],
   "source": [
    "# pip install pandas-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T20:44:17.366201Z",
     "iopub.status.busy": "2022-05-17T20:44:17.365313Z",
     "iopub.status.idle": "2022-05-17T20:44:19.275321Z",
     "shell.execute_reply": "2022-05-17T20:44:19.27438Z",
     "shell.execute_reply.started": "2022-05-17T20:44:17.366163Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# добавляем в графики красивости seaborn:\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas_profiling\n",
    "\n",
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T20:44:19.283652Z",
     "iopub.status.busy": "2022-05-17T20:44:19.283338Z",
     "iopub.status.idle": "2022-05-17T20:44:24.4308Z",
     "shell.execute_reply": "2022-05-17T20:44:24.429774Z",
     "shell.execute_reply.started": "2022-05-17T20:44:19.283607Z"
    }
   },
   "outputs": [],
   "source": [
    "#загрузка данных\n",
    "data = pd.read_csv('https://drive.google.com/uc?export=download&confirm=no_antivirus&id=1TPaBgFKxPhXCaVrdmHnb9wvoYcZESfBO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T20:44:24.432499Z",
     "iopub.status.busy": "2022-05-17T20:44:24.432288Z",
     "iopub.status.idle": "2022-05-17T20:44:24.487351Z",
     "shell.execute_reply": "2022-05-17T20:44:24.486555Z",
     "shell.execute_reply.started": "2022-05-17T20:44:24.432473Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "      <th>Unnamed: 18</th>\n",
       "      <th>Unnamed: 19</th>\n",
       "      <th>Unnamed: 20</th>\n",
       "      <th>Unnamed: 21</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "      <th>Unnamed: 24</th>\n",
       "      <th>Unnamed: 25</th>\n",
       "      <th>Unnamed: 26</th>\n",
       "      <th>Unnamed: 27</th>\n",
       "      <th>Unnamed: 28</th>\n",
       "      <th>Unnamed: 29</th>\n",
       "      <th>Unnamed: 30</th>\n",
       "      <th>Unnamed: 31</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "      <th>Unnamed: 33</th>\n",
       "      <th>Unnamed: 34</th>\n",
       "      <th>Unnamed: 35</th>\n",
       "      <th>Unnamed: 36</th>\n",
       "      <th>Unnamed: 37</th>\n",
       "      <th>Unnamed: 38</th>\n",
       "      <th>Unnamed: 39</th>\n",
       "      <th>Unnamed: 40</th>\n",
       "      <th>Unnamed: 41</th>\n",
       "      <th>Unnamed: 42</th>\n",
       "      <th>Unnamed: 43</th>\n",
       "      <th>Unnamed: 44</th>\n",
       "      <th>Unnamed: 45</th>\n",
       "      <th>Unnamed: 46</th>\n",
       "      <th>Unnamed: 47</th>\n",
       "      <th>Unnamed: 48</th>\n",
       "      <th>Unnamed: 49</th>\n",
       "      <th>Unnamed: 50</th>\n",
       "      <th>Unnamed: 51</th>\n",
       "      <th>Unnamed: 52</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Timestamp</td>\n",
       "      <td>FIT101</td>\n",
       "      <td>LIT101</td>\n",
       "      <td>MV101</td>\n",
       "      <td>P101</td>\n",
       "      <td>P102</td>\n",
       "      <td>AIT201</td>\n",
       "      <td>AIT202</td>\n",
       "      <td>AIT203</td>\n",
       "      <td>FIT201</td>\n",
       "      <td>MV201</td>\n",
       "      <td>P201</td>\n",
       "      <td>P202</td>\n",
       "      <td>P203</td>\n",
       "      <td>P204</td>\n",
       "      <td>P205</td>\n",
       "      <td>P206</td>\n",
       "      <td>DPIT301</td>\n",
       "      <td>FIT301</td>\n",
       "      <td>LIT301</td>\n",
       "      <td>MV301</td>\n",
       "      <td>MV302</td>\n",
       "      <td>MV303</td>\n",
       "      <td>MV304</td>\n",
       "      <td>P301</td>\n",
       "      <td>P302</td>\n",
       "      <td>AIT401</td>\n",
       "      <td>AIT402</td>\n",
       "      <td>FIT401</td>\n",
       "      <td>LIT401</td>\n",
       "      <td>P401</td>\n",
       "      <td>P402</td>\n",
       "      <td>P403</td>\n",
       "      <td>P404</td>\n",
       "      <td>UV401</td>\n",
       "      <td>AIT501</td>\n",
       "      <td>AIT502</td>\n",
       "      <td>AIT503</td>\n",
       "      <td>AIT504</td>\n",
       "      <td>FIT501</td>\n",
       "      <td>FIT502</td>\n",
       "      <td>FIT503</td>\n",
       "      <td>FIT504</td>\n",
       "      <td>P501</td>\n",
       "      <td>P502</td>\n",
       "      <td>PIT501</td>\n",
       "      <td>PIT502</td>\n",
       "      <td>PIT503</td>\n",
       "      <td>FIT601</td>\n",
       "      <td>P601</td>\n",
       "      <td>P602</td>\n",
       "      <td>P603</td>\n",
       "      <td>Normal/Attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28/12/2015 10:00:00 AM</td>\n",
       "      <td>2.427057</td>\n",
       "      <td>522.8467</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>262.0161</td>\n",
       "      <td>8.396437</td>\n",
       "      <td>328.6337</td>\n",
       "      <td>2.445391</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19.74838</td>\n",
       "      <td>2.206835</td>\n",
       "      <td>956.1651</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>148.808</td>\n",
       "      <td>156.0882</td>\n",
       "      <td>1.713517</td>\n",
       "      <td>942.0662</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.878621</td>\n",
       "      <td>145.1166</td>\n",
       "      <td>264.5475</td>\n",
       "      <td>12.03538</td>\n",
       "      <td>1.723789</td>\n",
       "      <td>1.279621</td>\n",
       "      <td>0.7352687</td>\n",
       "      <td>0.3077859</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>250.8652</td>\n",
       "      <td>1.649953</td>\n",
       "      <td>189.5988</td>\n",
       "      <td>0.000128152</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28/12/2015 10:00:01 AM</td>\n",
       "      <td>2.446274</td>\n",
       "      <td>522.886</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>262.0161</td>\n",
       "      <td>8.396437</td>\n",
       "      <td>328.6337</td>\n",
       "      <td>2.445391</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19.74838</td>\n",
       "      <td>2.208244</td>\n",
       "      <td>956.1651</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>148.808</td>\n",
       "      <td>156.0882</td>\n",
       "      <td>1.715952</td>\n",
       "      <td>942.0277</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.878621</td>\n",
       "      <td>145.1166</td>\n",
       "      <td>264.5475</td>\n",
       "      <td>12.03538</td>\n",
       "      <td>1.723789</td>\n",
       "      <td>1.297554</td>\n",
       "      <td>0.7352687</td>\n",
       "      <td>0.3077859</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>250.8652</td>\n",
       "      <td>1.649953</td>\n",
       "      <td>189.6789</td>\n",
       "      <td>0.000128152</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28/12/2015 10:00:02 AM</td>\n",
       "      <td>2.489191</td>\n",
       "      <td>522.8467</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>262.0161</td>\n",
       "      <td>8.394514</td>\n",
       "      <td>328.6337</td>\n",
       "      <td>2.442316</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19.69076</td>\n",
       "      <td>2.208628</td>\n",
       "      <td>956.4855</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>148.808</td>\n",
       "      <td>156.0882</td>\n",
       "      <td>1.715952</td>\n",
       "      <td>941.8739</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.878621</td>\n",
       "      <td>145.1166</td>\n",
       "      <td>264.5475</td>\n",
       "      <td>12.03538</td>\n",
       "      <td>1.723404</td>\n",
       "      <td>1.293967</td>\n",
       "      <td>0.7352687</td>\n",
       "      <td>0.3086186</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>250.8812</td>\n",
       "      <td>1.649953</td>\n",
       "      <td>189.6789</td>\n",
       "      <td>0.000128152</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28/12/2015 10:00:03 AM</td>\n",
       "      <td>2.53435</td>\n",
       "      <td>522.9645</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>262.0161</td>\n",
       "      <td>8.394514</td>\n",
       "      <td>328.6337</td>\n",
       "      <td>2.442316</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19.69076</td>\n",
       "      <td>2.208628</td>\n",
       "      <td>956.806</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>148.808</td>\n",
       "      <td>156.0882</td>\n",
       "      <td>1.71467</td>\n",
       "      <td>941.797</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.878621</td>\n",
       "      <td>145.0141</td>\n",
       "      <td>264.5475</td>\n",
       "      <td>12.03538</td>\n",
       "      <td>1.723404</td>\n",
       "      <td>1.281158</td>\n",
       "      <td>0.7352687</td>\n",
       "      <td>0.3086186</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>250.8812</td>\n",
       "      <td>1.649953</td>\n",
       "      <td>189.6148</td>\n",
       "      <td>0.000128152</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Unnamed: 0 Unnamed: 1 Unnamed: 2 Unnamed: 3 Unnamed: 4  \\\n",
       "0                Timestamp     FIT101     LIT101      MV101       P101   \n",
       "1   28/12/2015 10:00:00 AM   2.427057   522.8467          2          2   \n",
       "2   28/12/2015 10:00:01 AM   2.446274    522.886          2          2   \n",
       "3   28/12/2015 10:00:02 AM   2.489191   522.8467          2          2   \n",
       "4   28/12/2015 10:00:03 AM    2.53435   522.9645          2          2   \n",
       "\n",
       "  Unnamed: 5 Unnamed: 6 Unnamed: 7 Unnamed: 8 Unnamed: 9 Unnamed: 10  \\\n",
       "0       P102     AIT201     AIT202     AIT203     FIT201       MV201   \n",
       "1          1   262.0161   8.396437   328.6337   2.445391           2   \n",
       "2          1   262.0161   8.396437   328.6337   2.445391           2   \n",
       "3          1   262.0161   8.394514   328.6337   2.442316           2   \n",
       "4          1   262.0161   8.394514   328.6337   2.442316           2   \n",
       "\n",
       "  Unnamed: 11 Unnamed: 12 Unnamed: 13 Unnamed: 14 Unnamed: 15 Unnamed: 16  \\\n",
       "0        P201        P202        P203        P204        P205        P206   \n",
       "1           1           1           2           1           2           1   \n",
       "2           1           1           2           1           2           1   \n",
       "3           1           1           2           1           2           1   \n",
       "4           1           1           2           1           2           1   \n",
       "\n",
       "  Unnamed: 17 Unnamed: 18 Unnamed: 19 Unnamed: 20 Unnamed: 21 Unnamed: 22  \\\n",
       "0     DPIT301      FIT301      LIT301       MV301       MV302       MV303   \n",
       "1    19.74838    2.206835    956.1651           1           2           1   \n",
       "2    19.74838    2.208244    956.1651           1           2           1   \n",
       "3    19.69076    2.208628    956.4855           1           2           1   \n",
       "4    19.69076    2.208628     956.806           1           2           1   \n",
       "\n",
       "  Unnamed: 23 Unnamed: 24 Unnamed: 25 Unnamed: 26 Unnamed: 27 Unnamed: 28  \\\n",
       "0       MV304        P301        P302      AIT401      AIT402      FIT401   \n",
       "1           1           1           2     148.808    156.0882    1.713517   \n",
       "2           1           1           2     148.808    156.0882    1.715952   \n",
       "3           1           1           2     148.808    156.0882    1.715952   \n",
       "4           1           1           2     148.808    156.0882     1.71467   \n",
       "\n",
       "  Unnamed: 29 Unnamed: 30 Unnamed: 31 Unnamed: 32 Unnamed: 33 Unnamed: 34  \\\n",
       "0      LIT401        P401        P402        P403        P404       UV401   \n",
       "1    942.0662           1           2           1           1           2   \n",
       "2    942.0277           1           2           1           1           2   \n",
       "3    941.8739           1           2           1           1           2   \n",
       "4     941.797           1           2           1           1           2   \n",
       "\n",
       "  Unnamed: 35 Unnamed: 36 Unnamed: 37 Unnamed: 38 Unnamed: 39 Unnamed: 40  \\\n",
       "0      AIT501      AIT502      AIT503      AIT504      FIT501      FIT502   \n",
       "1    7.878621    145.1166    264.5475    12.03538    1.723789    1.279621   \n",
       "2    7.878621    145.1166    264.5475    12.03538    1.723789    1.297554   \n",
       "3    7.878621    145.1166    264.5475    12.03538    1.723404    1.293967   \n",
       "4    7.878621    145.0141    264.5475    12.03538    1.723404    1.281158   \n",
       "\n",
       "  Unnamed: 41 Unnamed: 42 Unnamed: 43 Unnamed: 44 Unnamed: 45 Unnamed: 46  \\\n",
       "0      FIT503      FIT504        P501        P502      PIT501      PIT502   \n",
       "1   0.7352687   0.3077859           2           1    250.8652    1.649953   \n",
       "2   0.7352687   0.3077859           2           1    250.8652    1.649953   \n",
       "3   0.7352687   0.3086186           2           1    250.8812    1.649953   \n",
       "4   0.7352687   0.3086186           2           1    250.8812    1.649953   \n",
       "\n",
       "  Unnamed: 47  Unnamed: 48 Unnamed: 49 Unnamed: 50 Unnamed: 51    Unnamed: 52  \n",
       "0      PIT503       FIT601        P601        P602        P603  Normal/Attack  \n",
       "1    189.5988  0.000128152           1           1           1         Normal  \n",
       "2    189.6789  0.000128152           1           1           1         Normal  \n",
       "3    189.6789  0.000128152           1           1           1         Normal  \n",
       "4    189.6148  0.000128152           1           1           1         Normal  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T20:44:24.489733Z",
     "iopub.status.busy": "2022-05-17T20:44:24.489119Z",
     "iopub.status.idle": "2022-05-17T20:44:24.796588Z",
     "shell.execute_reply": "2022-05-17T20:44:24.795634Z",
     "shell.execute_reply.started": "2022-05-17T20:44:24.489689Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>FIT101</th>\n",
       "      <th>LIT101</th>\n",
       "      <th>MV101</th>\n",
       "      <th>P101</th>\n",
       "      <th>P102</th>\n",
       "      <th>AIT201</th>\n",
       "      <th>AIT202</th>\n",
       "      <th>AIT203</th>\n",
       "      <th>FIT201</th>\n",
       "      <th>MV201</th>\n",
       "      <th>P201</th>\n",
       "      <th>P202</th>\n",
       "      <th>P203</th>\n",
       "      <th>P204</th>\n",
       "      <th>P205</th>\n",
       "      <th>P206</th>\n",
       "      <th>DPIT301</th>\n",
       "      <th>FIT301</th>\n",
       "      <th>LIT301</th>\n",
       "      <th>MV301</th>\n",
       "      <th>MV302</th>\n",
       "      <th>MV303</th>\n",
       "      <th>MV304</th>\n",
       "      <th>P301</th>\n",
       "      <th>P302</th>\n",
       "      <th>AIT401</th>\n",
       "      <th>AIT402</th>\n",
       "      <th>FIT401</th>\n",
       "      <th>LIT401</th>\n",
       "      <th>P401</th>\n",
       "      <th>P402</th>\n",
       "      <th>P403</th>\n",
       "      <th>P404</th>\n",
       "      <th>UV401</th>\n",
       "      <th>AIT501</th>\n",
       "      <th>AIT502</th>\n",
       "      <th>AIT503</th>\n",
       "      <th>AIT504</th>\n",
       "      <th>FIT501</th>\n",
       "      <th>FIT502</th>\n",
       "      <th>FIT503</th>\n",
       "      <th>FIT504</th>\n",
       "      <th>P501</th>\n",
       "      <th>P502</th>\n",
       "      <th>PIT501</th>\n",
       "      <th>PIT502</th>\n",
       "      <th>PIT503</th>\n",
       "      <th>FIT601</th>\n",
       "      <th>P601</th>\n",
       "      <th>P602</th>\n",
       "      <th>P603</th>\n",
       "      <th>Normal/Attack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28/12/2015 10:00:00 AM</td>\n",
       "      <td>2.427057</td>\n",
       "      <td>522.8467</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>262.0161</td>\n",
       "      <td>8.396437</td>\n",
       "      <td>328.6337</td>\n",
       "      <td>2.445391</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19.74838</td>\n",
       "      <td>2.206835</td>\n",
       "      <td>956.1651</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>148.808</td>\n",
       "      <td>156.0882</td>\n",
       "      <td>1.713517</td>\n",
       "      <td>942.0662</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.878621</td>\n",
       "      <td>145.1166</td>\n",
       "      <td>264.5475</td>\n",
       "      <td>12.03538</td>\n",
       "      <td>1.723789</td>\n",
       "      <td>1.279621</td>\n",
       "      <td>0.7352687</td>\n",
       "      <td>0.3077859</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>250.8652</td>\n",
       "      <td>1.649953</td>\n",
       "      <td>189.5988</td>\n",
       "      <td>0.000128152</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28/12/2015 10:00:01 AM</td>\n",
       "      <td>2.446274</td>\n",
       "      <td>522.886</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>262.0161</td>\n",
       "      <td>8.396437</td>\n",
       "      <td>328.6337</td>\n",
       "      <td>2.445391</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19.74838</td>\n",
       "      <td>2.208244</td>\n",
       "      <td>956.1651</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>148.808</td>\n",
       "      <td>156.0882</td>\n",
       "      <td>1.715952</td>\n",
       "      <td>942.0277</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.878621</td>\n",
       "      <td>145.1166</td>\n",
       "      <td>264.5475</td>\n",
       "      <td>12.03538</td>\n",
       "      <td>1.723789</td>\n",
       "      <td>1.297554</td>\n",
       "      <td>0.7352687</td>\n",
       "      <td>0.3077859</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>250.8652</td>\n",
       "      <td>1.649953</td>\n",
       "      <td>189.6789</td>\n",
       "      <td>0.000128152</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28/12/2015 10:00:02 AM</td>\n",
       "      <td>2.489191</td>\n",
       "      <td>522.8467</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>262.0161</td>\n",
       "      <td>8.394514</td>\n",
       "      <td>328.6337</td>\n",
       "      <td>2.442316</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19.69076</td>\n",
       "      <td>2.208628</td>\n",
       "      <td>956.4855</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>148.808</td>\n",
       "      <td>156.0882</td>\n",
       "      <td>1.715952</td>\n",
       "      <td>941.8739</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.878621</td>\n",
       "      <td>145.1166</td>\n",
       "      <td>264.5475</td>\n",
       "      <td>12.03538</td>\n",
       "      <td>1.723404</td>\n",
       "      <td>1.293967</td>\n",
       "      <td>0.7352687</td>\n",
       "      <td>0.3086186</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>250.8812</td>\n",
       "      <td>1.649953</td>\n",
       "      <td>189.6789</td>\n",
       "      <td>0.000128152</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28/12/2015 10:00:03 AM</td>\n",
       "      <td>2.53435</td>\n",
       "      <td>522.9645</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>262.0161</td>\n",
       "      <td>8.394514</td>\n",
       "      <td>328.6337</td>\n",
       "      <td>2.442316</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19.69076</td>\n",
       "      <td>2.208628</td>\n",
       "      <td>956.806</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>148.808</td>\n",
       "      <td>156.0882</td>\n",
       "      <td>1.71467</td>\n",
       "      <td>941.797</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.878621</td>\n",
       "      <td>145.0141</td>\n",
       "      <td>264.5475</td>\n",
       "      <td>12.03538</td>\n",
       "      <td>1.723404</td>\n",
       "      <td>1.281158</td>\n",
       "      <td>0.7352687</td>\n",
       "      <td>0.3086186</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>250.8812</td>\n",
       "      <td>1.649953</td>\n",
       "      <td>189.6148</td>\n",
       "      <td>0.000128152</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28/12/2015 10:00:04 AM</td>\n",
       "      <td>2.56926</td>\n",
       "      <td>523.4748</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>262.0161</td>\n",
       "      <td>8.394514</td>\n",
       "      <td>328.6337</td>\n",
       "      <td>2.443085</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19.69076</td>\n",
       "      <td>2.208628</td>\n",
       "      <td>957.0864</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>148.808</td>\n",
       "      <td>156.0882</td>\n",
       "      <td>1.71467</td>\n",
       "      <td>942.22</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.878621</td>\n",
       "      <td>144.8859</td>\n",
       "      <td>264.5475</td>\n",
       "      <td>12.03538</td>\n",
       "      <td>1.723404</td>\n",
       "      <td>1.281158</td>\n",
       "      <td>0.7352687</td>\n",
       "      <td>0.3086186</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>250.8812</td>\n",
       "      <td>1.649953</td>\n",
       "      <td>189.5027</td>\n",
       "      <td>0.000128152</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0                Timestamp    FIT101    LIT101  MV101 P101 P102    AIT201  \\\n",
       "1   28/12/2015 10:00:00 AM  2.427057  522.8467      2    2    1  262.0161   \n",
       "2   28/12/2015 10:00:01 AM  2.446274   522.886      2    2    1  262.0161   \n",
       "3   28/12/2015 10:00:02 AM  2.489191  522.8467      2    2    1  262.0161   \n",
       "4   28/12/2015 10:00:03 AM   2.53435  522.9645      2    2    1  262.0161   \n",
       "5   28/12/2015 10:00:04 AM   2.56926  523.4748      2    2    1  262.0161   \n",
       "\n",
       "0    AIT202    AIT203    FIT201  MV201  P201  P202 P203  P204 P205 P206  \\\n",
       "1  8.396437  328.6337  2.445391      2     1     1    2     1    2    1   \n",
       "2  8.396437  328.6337  2.445391      2     1     1    2     1    2    1   \n",
       "3  8.394514  328.6337  2.442316      2     1     1    2     1    2    1   \n",
       "4  8.394514  328.6337  2.442316      2     1     1    2     1    2    1   \n",
       "5  8.394514  328.6337  2.443085      2     1     1    2     1    2    1   \n",
       "\n",
       "0   DPIT301    FIT301    LIT301 MV301 MV302  MV303 MV304 P301 P302   AIT401  \\\n",
       "1  19.74838  2.206835  956.1651     1     2      1     1    1    2  148.808   \n",
       "2  19.74838  2.208244  956.1651     1     2      1     1    1    2  148.808   \n",
       "3  19.69076  2.208628  956.4855     1     2      1     1    1    2  148.808   \n",
       "4  19.69076  2.208628   956.806     1     2      1     1    1    2  148.808   \n",
       "5  19.69076  2.208628  957.0864     1     2      1     1    1    2  148.808   \n",
       "\n",
       "0    AIT402    FIT401    LIT401 P401 P402 P403 P404 UV401    AIT501    AIT502  \\\n",
       "1  156.0882  1.713517  942.0662    1    2    1    1     2  7.878621  145.1166   \n",
       "2  156.0882  1.715952  942.0277    1    2    1    1     2  7.878621  145.1166   \n",
       "3  156.0882  1.715952  941.8739    1    2    1    1     2  7.878621  145.1166   \n",
       "4  156.0882   1.71467   941.797    1    2    1    1     2  7.878621  145.0141   \n",
       "5  156.0882   1.71467    942.22    1    2    1    1     2  7.878621  144.8859   \n",
       "\n",
       "0    AIT503    AIT504    FIT501    FIT502     FIT503     FIT504 P501 P502  \\\n",
       "1  264.5475  12.03538  1.723789  1.279621  0.7352687  0.3077859    2    1   \n",
       "2  264.5475  12.03538  1.723789  1.297554  0.7352687  0.3077859    2    1   \n",
       "3  264.5475  12.03538  1.723404  1.293967  0.7352687  0.3086186    2    1   \n",
       "4  264.5475  12.03538  1.723404  1.281158  0.7352687  0.3086186    2    1   \n",
       "5  264.5475  12.03538  1.723404  1.281158  0.7352687  0.3086186    2    1   \n",
       "\n",
       "0    PIT501    PIT502    PIT503       FIT601 P601 P602 P603 Normal/Attack  \n",
       "1  250.8652  1.649953  189.5988  0.000128152    1    1    1        Normal  \n",
       "2  250.8652  1.649953  189.6789  0.000128152    1    1    1        Normal  \n",
       "3  250.8812  1.649953  189.6789  0.000128152    1    1    1        Normal  \n",
       "4  250.8812  1.649953  189.6148  0.000128152    1    1    1        Normal  \n",
       "5  250.8812  1.649953  189.5027  0.000128152    1    1    1        Normal  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Сделаем первую строку названиями столбцов\n",
    "data.columns = data.iloc[0]\n",
    "data = data.reindex(data.index.drop(0))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T20:44:24.798594Z",
     "iopub.status.busy": "2022-05-17T20:44:24.798121Z",
     "iopub.status.idle": "2022-05-17T20:44:26.721035Z",
     "shell.execute_reply": "2022-05-17T20:44:26.719993Z",
     "shell.execute_reply.started": "2022-05-17T20:44:24.79855Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер датасета data: (449919, 53)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 449919 entries, 1 to 449919\n",
      "Data columns (total 53 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0    Timestamp     449919 non-null  object\n",
      " 1   FIT101         449919 non-null  object\n",
      " 2   LIT101         449919 non-null  object\n",
      " 3    MV101         449919 non-null  object\n",
      " 4   P101           449919 non-null  object\n",
      " 5   P102           449919 non-null  object\n",
      " 6    AIT201        449919 non-null  object\n",
      " 7   AIT202         449919 non-null  object\n",
      " 8   AIT203         449919 non-null  object\n",
      " 9   FIT201         449919 non-null  object\n",
      " 10   MV201         449919 non-null  object\n",
      " 11   P201          449919 non-null  object\n",
      " 12   P202          449919 non-null  object\n",
      " 13  P203           449919 non-null  object\n",
      " 14   P204          449919 non-null  object\n",
      " 15  P205           449919 non-null  object\n",
      " 16  P206           449919 non-null  object\n",
      " 17  DPIT301        449919 non-null  object\n",
      " 18  FIT301         449919 non-null  object\n",
      " 19  LIT301         449919 non-null  object\n",
      " 20  MV301          449919 non-null  object\n",
      " 21  MV302          449919 non-null  object\n",
      " 22   MV303         449919 non-null  object\n",
      " 23  MV304          449919 non-null  object\n",
      " 24  P301           449919 non-null  object\n",
      " 25  P302           449919 non-null  object\n",
      " 26  AIT401         449919 non-null  object\n",
      " 27  AIT402         449919 non-null  object\n",
      " 28  FIT401         449919 non-null  object\n",
      " 29  LIT401         449919 non-null  object\n",
      " 30  P401           449919 non-null  object\n",
      " 31  P402           449919 non-null  object\n",
      " 32  P403           449919 non-null  object\n",
      " 33  P404           449919 non-null  object\n",
      " 34  UV401          449919 non-null  object\n",
      " 35  AIT501         449919 non-null  object\n",
      " 36  AIT502         449919 non-null  object\n",
      " 37  AIT503         449919 non-null  object\n",
      " 38  AIT504         449919 non-null  object\n",
      " 39  FIT501         449919 non-null  object\n",
      " 40  FIT502         449919 non-null  object\n",
      " 41  FIT503         449919 non-null  object\n",
      " 42  FIT504         449919 non-null  object\n",
      " 43  P501           449919 non-null  object\n",
      " 44  P502           449919 non-null  object\n",
      " 45  PIT501         449919 non-null  object\n",
      " 46  PIT502         449919 non-null  object\n",
      " 47  PIT503         449919 non-null  object\n",
      " 48  FIT601         449919 non-null  object\n",
      " 49  P601           449919 non-null  object\n",
      " 50  P602           449919 non-null  object\n",
      " 51  P603           449919 non-null  object\n",
      " 52  Normal/Attack  449919 non-null  object\n",
      "dtypes: object(53)\n",
      "memory usage: 185.4+ MB\n"
     ]
    }
   ],
   "source": [
    "print(\"Размер датасета data:\", data.shape)\n",
    "print()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T20:44:26.722576Z",
     "iopub.status.busy": "2022-05-17T20:44:26.722263Z",
     "iopub.status.idle": "2022-05-17T20:44:26.726761Z",
     "shell.execute_reply": "2022-05-17T20:44:26.726095Z",
     "shell.execute_reply.started": "2022-05-17T20:44:26.72254Z"
    }
   },
   "outputs": [],
   "source": [
    "# Убрать пустые пространства из названия столбцов\n",
    "data.columns = data.columns.str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T20:44:26.728176Z",
     "iopub.status.busy": "2022-05-17T20:44:26.727819Z",
     "iopub.status.idle": "2022-05-17T20:44:33.878187Z",
     "shell.execute_reply": "2022-05-17T20:44:33.877276Z",
     "shell.execute_reply.started": "2022-05-17T20:44:26.728145Z"
    }
   },
   "outputs": [],
   "source": [
    "# Перевести все данные, которые воможно в цифровой формат\n",
    "df = data.apply(pd.to_numeric, errors='ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T20:44:33.879675Z",
     "iopub.status.busy": "2022-05-17T20:44:33.879427Z",
     "iopub.status.idle": "2022-05-17T20:44:34.034728Z",
     "shell.execute_reply": "2022-05-17T20:44:34.033682Z",
     "shell.execute_reply.started": "2022-05-17T20:44:33.87964Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер датасета data: (449919, 53)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 449919 entries, 1 to 449919\n",
      "Data columns (total 53 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   Timestamp      449919 non-null  object \n",
      " 1   FIT101         449919 non-null  float64\n",
      " 2   LIT101         449919 non-null  float64\n",
      " 3   MV101          449919 non-null  int64  \n",
      " 4   P101           449919 non-null  int64  \n",
      " 5   P102           449919 non-null  int64  \n",
      " 6   AIT201         449919 non-null  float64\n",
      " 7   AIT202         449919 non-null  float64\n",
      " 8   AIT203         449919 non-null  float64\n",
      " 9   FIT201         449919 non-null  float64\n",
      " 10  MV201          449919 non-null  int64  \n",
      " 11  P201           449919 non-null  int64  \n",
      " 12  P202           449919 non-null  int64  \n",
      " 13  P203           449919 non-null  int64  \n",
      " 14  P204           449919 non-null  int64  \n",
      " 15  P205           449919 non-null  int64  \n",
      " 16  P206           449919 non-null  int64  \n",
      " 17  DPIT301        449919 non-null  float64\n",
      " 18  FIT301         449919 non-null  float64\n",
      " 19  LIT301         449919 non-null  float64\n",
      " 20  MV301          449919 non-null  int64  \n",
      " 21  MV302          449919 non-null  int64  \n",
      " 22  MV303          449919 non-null  int64  \n",
      " 23  MV304          449919 non-null  int64  \n",
      " 24  P301           449919 non-null  int64  \n",
      " 25  P302           449919 non-null  int64  \n",
      " 26  AIT401         449919 non-null  float64\n",
      " 27  AIT402         449919 non-null  float64\n",
      " 28  FIT401         449919 non-null  float64\n",
      " 29  LIT401         449919 non-null  float64\n",
      " 30  P401           449919 non-null  int64  \n",
      " 31  P402           449919 non-null  int64  \n",
      " 32  P403           449919 non-null  int64  \n",
      " 33  P404           449919 non-null  int64  \n",
      " 34  UV401          449919 non-null  int64  \n",
      " 35  AIT501         449919 non-null  float64\n",
      " 36  AIT502         449919 non-null  float64\n",
      " 37  AIT503         449919 non-null  float64\n",
      " 38  AIT504         449919 non-null  float64\n",
      " 39  FIT501         449919 non-null  float64\n",
      " 40  FIT502         449919 non-null  float64\n",
      " 41  FIT503         449919 non-null  float64\n",
      " 42  FIT504         449919 non-null  float64\n",
      " 43  P501           449919 non-null  int64  \n",
      " 44  P502           449919 non-null  int64  \n",
      " 45  PIT501         449919 non-null  float64\n",
      " 46  PIT502         449919 non-null  float64\n",
      " 47  PIT503         449919 non-null  float64\n",
      " 48  FIT601         449919 non-null  float64\n",
      " 49  P601           449919 non-null  int64  \n",
      " 50  P602           449919 non-null  int64  \n",
      " 51  P603           449919 non-null  int64  \n",
      " 52  Normal/Attack  449919 non-null  object \n",
      "dtypes: float64(25), int64(26), object(2)\n",
      "memory usage: 185.4+ MB\n"
     ]
    }
   ],
   "source": [
    "print(\"Размер датасета data:\", df.shape)\n",
    "print()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T20:44:34.038844Z",
     "iopub.status.busy": "2022-05-17T20:44:34.038603Z",
     "iopub.status.idle": "2022-05-17T20:45:32.236067Z",
     "shell.execute_reply": "2022-05-17T20:45:32.235388Z",
     "shell.execute_reply.started": "2022-05-17T20:44:34.038817Z"
    }
   },
   "outputs": [],
   "source": [
    "# Переведем данные столбца 'Timestamp' в формат времени\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T20:45:32.237795Z",
     "iopub.status.busy": "2022-05-17T20:45:32.237041Z",
     "iopub.status.idle": "2022-05-17T20:45:32.993962Z",
     "shell.execute_reply": "2022-05-17T20:45:32.993102Z",
     "shell.execute_reply.started": "2022-05-17T20:45:32.237758Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIT101</th>\n",
       "      <th>LIT101</th>\n",
       "      <th>MV101</th>\n",
       "      <th>P101</th>\n",
       "      <th>P102</th>\n",
       "      <th>AIT201</th>\n",
       "      <th>AIT202</th>\n",
       "      <th>AIT203</th>\n",
       "      <th>FIT201</th>\n",
       "      <th>MV201</th>\n",
       "      <th>P201</th>\n",
       "      <th>P202</th>\n",
       "      <th>P203</th>\n",
       "      <th>P204</th>\n",
       "      <th>P205</th>\n",
       "      <th>P206</th>\n",
       "      <th>DPIT301</th>\n",
       "      <th>FIT301</th>\n",
       "      <th>LIT301</th>\n",
       "      <th>MV301</th>\n",
       "      <th>MV302</th>\n",
       "      <th>MV303</th>\n",
       "      <th>MV304</th>\n",
       "      <th>P301</th>\n",
       "      <th>P302</th>\n",
       "      <th>AIT401</th>\n",
       "      <th>AIT402</th>\n",
       "      <th>FIT401</th>\n",
       "      <th>LIT401</th>\n",
       "      <th>P401</th>\n",
       "      <th>P402</th>\n",
       "      <th>P403</th>\n",
       "      <th>P404</th>\n",
       "      <th>UV401</th>\n",
       "      <th>AIT501</th>\n",
       "      <th>AIT502</th>\n",
       "      <th>AIT503</th>\n",
       "      <th>AIT504</th>\n",
       "      <th>FIT501</th>\n",
       "      <th>FIT502</th>\n",
       "      <th>FIT503</th>\n",
       "      <th>FIT504</th>\n",
       "      <th>P501</th>\n",
       "      <th>P502</th>\n",
       "      <th>PIT501</th>\n",
       "      <th>PIT502</th>\n",
       "      <th>PIT503</th>\n",
       "      <th>FIT601</th>\n",
       "      <th>P601</th>\n",
       "      <th>P602</th>\n",
       "      <th>P603</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>449919.000000</td>\n",
       "      <td>449919.000000</td>\n",
       "      <td>449919.000000</td>\n",
       "      <td>449919.000000</td>\n",
       "      <td>449919.000000</td>\n",
       "      <td>449919.000000</td>\n",
       "      <td>449919.000000</td>\n",
       "      <td>449919.000000</td>\n",
       "      <td>449919.000000</td>\n",
       "      <td>449919.000000</td>\n",
       "      <td>449919.000000</td>\n",
       "      <td>449919.0</td>\n",
       "      <td>449919.000000</td>\n",
       "      <td>449919.000000</td>\n",
       "      <td>449919.000000</td>\n",
       "      <td>449919.000000</td>\n",
       "      <td>449919.000000</td>\n",
       "      <td>449919.000000</td>\n",
       "      <td>449919.000000</td>\n",
       "      <td>449919.000000</td>\n",
       "      <td>449919.000000</td>\n",
       "      <td>449919.000000</td>\n",
       "      <td>449919.000000</td>\n",
       "      <td>449919.0</td>\n",
       "      <td>449919.000000</td>\n",
       "      <td>449919.000000</td>\n",
       "      <td>449919.000000</td>\n",
       "      <td>449919.000000</td>\n",
       "      <td>449919.000000</td>\n",
       "      <td>449919.0</td>\n",
       "      <td>449919.000000</td>\n",
       "      <td>449919.000000</td>\n",
       "      <td>449919.0</td>\n",
       "      <td>449919.000000</td>\n",
       "      <td>449919.000000</td>\n",
       "      <td>449919.000000</td>\n",
       "      <td>449919.000000</td>\n",
       "      <td>449919.000000</td>\n",
       "      <td>449919.000000</td>\n",
       "      <td>449919.000000</td>\n",
       "      <td>449919.000000</td>\n",
       "      <td>449919.000000</td>\n",
       "      <td>449919.000000</td>\n",
       "      <td>449919.0</td>\n",
       "      <td>449919.000000</td>\n",
       "      <td>449919.000000</td>\n",
       "      <td>449919.000000</td>\n",
       "      <td>449919.000000</td>\n",
       "      <td>449919.0</td>\n",
       "      <td>449919.000000</td>\n",
       "      <td>449919.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.714346</td>\n",
       "      <td>607.019967</td>\n",
       "      <td>1.665335</td>\n",
       "      <td>1.693251</td>\n",
       "      <td>1.006946</td>\n",
       "      <td>210.297302</td>\n",
       "      <td>8.528535</td>\n",
       "      <td>320.301478</td>\n",
       "      <td>1.702908</td>\n",
       "      <td>1.691584</td>\n",
       "      <td>1.121068</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.690689</td>\n",
       "      <td>1.000124</td>\n",
       "      <td>1.691131</td>\n",
       "      <td>1.000122</td>\n",
       "      <td>15.827634</td>\n",
       "      <td>1.713555</td>\n",
       "      <td>910.076801</td>\n",
       "      <td>1.007321</td>\n",
       "      <td>1.749655</td>\n",
       "      <td>1.023349</td>\n",
       "      <td>1.101163</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.772946</td>\n",
       "      <td>148.805855</td>\n",
       "      <td>161.990135</td>\n",
       "      <td>1.590214</td>\n",
       "      <td>833.542913</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.928792</td>\n",
       "      <td>1.000133</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.925849</td>\n",
       "      <td>7.787358</td>\n",
       "      <td>147.509939</td>\n",
       "      <td>264.789668</td>\n",
       "      <td>14.504030</td>\n",
       "      <td>1.603014</td>\n",
       "      <td>1.195462</td>\n",
       "      <td>0.679549</td>\n",
       "      <td>0.283806</td>\n",
       "      <td>1.925862</td>\n",
       "      <td>1.0</td>\n",
       "      <td>232.173817</td>\n",
       "      <td>1.013408</td>\n",
       "      <td>174.714484</td>\n",
       "      <td>0.016566</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.009099</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.191716</td>\n",
       "      <td>125.303003</td>\n",
       "      <td>0.482323</td>\n",
       "      <td>0.461145</td>\n",
       "      <td>0.083051</td>\n",
       "      <td>35.157909</td>\n",
       "      <td>0.114844</td>\n",
       "      <td>16.631029</td>\n",
       "      <td>1.130277</td>\n",
       "      <td>0.470611</td>\n",
       "      <td>0.326207</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.462210</td>\n",
       "      <td>0.011156</td>\n",
       "      <td>0.462027</td>\n",
       "      <td>0.011056</td>\n",
       "      <td>7.740243</td>\n",
       "      <td>0.907519</td>\n",
       "      <td>80.522063</td>\n",
       "      <td>0.122666</td>\n",
       "      <td>0.448330</td>\n",
       "      <td>0.181441</td>\n",
       "      <td>0.324082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.418928</td>\n",
       "      <td>0.003889</td>\n",
       "      <td>44.740211</td>\n",
       "      <td>0.449035</td>\n",
       "      <td>186.068540</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.257173</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.262017</td>\n",
       "      <td>0.084308</td>\n",
       "      <td>21.429151</td>\n",
       "      <td>6.542092</td>\n",
       "      <td>7.944618</td>\n",
       "      <td>0.444681</td>\n",
       "      <td>0.331968</td>\n",
       "      <td>0.189503</td>\n",
       "      <td>0.080924</td>\n",
       "      <td>0.261995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.750930</td>\n",
       "      <td>0.412723</td>\n",
       "      <td>47.479809</td>\n",
       "      <td>0.159603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094956</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>189.826300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>168.033800</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>285.337100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>364.386300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>148.759900</td>\n",
       "      <td>140.835700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>243.014600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.432902</td>\n",
       "      <td>129.838500</td>\n",
       "      <td>244.873100</td>\n",
       "      <td>9.536016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.468726</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.140220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>510.011100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>177.102000</td>\n",
       "      <td>8.441618</td>\n",
       "      <td>306.383000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.316220</td>\n",
       "      <td>2.194664</td>\n",
       "      <td>836.444200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>148.803200</td>\n",
       "      <td>146.116400</td>\n",
       "      <td>1.710441</td>\n",
       "      <td>819.097700</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.772879</td>\n",
       "      <td>138.990000</td>\n",
       "      <td>259.965400</td>\n",
       "      <td>13.035120</td>\n",
       "      <td>1.719559</td>\n",
       "      <td>1.272576</td>\n",
       "      <td>0.730660</td>\n",
       "      <td>0.306249</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>248.029400</td>\n",
       "      <td>0.816967</td>\n",
       "      <td>186.698900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.477020</td>\n",
       "      <td>530.422500</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>193.508100</td>\n",
       "      <td>8.551525</td>\n",
       "      <td>321.661100</td>\n",
       "      <td>2.446673</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.898840</td>\n",
       "      <td>2.201582</td>\n",
       "      <td>924.682800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>148.808000</td>\n",
       "      <td>150.166600</td>\n",
       "      <td>1.717361</td>\n",
       "      <td>884.427100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.797873</td>\n",
       "      <td>142.912100</td>\n",
       "      <td>264.387300</td>\n",
       "      <td>14.611640</td>\n",
       "      <td>1.726993</td>\n",
       "      <td>1.286410</td>\n",
       "      <td>0.732708</td>\n",
       "      <td>0.306633</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>249.295100</td>\n",
       "      <td>0.961138</td>\n",
       "      <td>187.724300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.577907</td>\n",
       "      <td>727.432100</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>253.845200</td>\n",
       "      <td>8.610806</td>\n",
       "      <td>331.684200</td>\n",
       "      <td>2.454362</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.116530</td>\n",
       "      <td>2.207091</td>\n",
       "      <td>977.794200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>148.808000</td>\n",
       "      <td>153.652900</td>\n",
       "      <td>1.724153</td>\n",
       "      <td>937.375100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.840810</td>\n",
       "      <td>144.706500</td>\n",
       "      <td>269.129700</td>\n",
       "      <td>15.419120</td>\n",
       "      <td>1.733145</td>\n",
       "      <td>1.300115</td>\n",
       "      <td>0.734885</td>\n",
       "      <td>0.308106</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>250.881200</td>\n",
       "      <td>1.409669</td>\n",
       "      <td>189.118200</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.760145</td>\n",
       "      <td>925.032300</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>267.719800</td>\n",
       "      <td>8.733210</td>\n",
       "      <td>384.465500</td>\n",
       "      <td>2.826899</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>2.376197</td>\n",
       "      <td>1201.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>148.856100</td>\n",
       "      <td>333.811800</td>\n",
       "      <td>1.744914</td>\n",
       "      <td>1002.781000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.307037</td>\n",
       "      <td>272.853100</td>\n",
       "      <td>297.263500</td>\n",
       "      <td>442.463500</td>\n",
       "      <td>1.753653</td>\n",
       "      <td>1.360318</td>\n",
       "      <td>0.741542</td>\n",
       "      <td>0.311693</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>254.341800</td>\n",
       "      <td>1.970333</td>\n",
       "      <td>191.986000</td>\n",
       "      <td>1.802710</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0             FIT101         LIT101          MV101           P101  \\\n",
       "count  449919.000000  449919.000000  449919.000000  449919.000000   \n",
       "mean        1.714346     607.019967       1.665335       1.693251   \n",
       "std         1.191716     125.303003       0.482323       0.461145   \n",
       "min         0.000000     189.826300       0.000000       1.000000   \n",
       "25%         0.000000     510.011100       1.000000       1.000000   \n",
       "50%         2.477020     530.422500       2.000000       2.000000   \n",
       "75%         2.577907     727.432100       2.000000       2.000000   \n",
       "max         2.760145     925.032300       2.000000       2.000000   \n",
       "\n",
       "0               P102         AIT201         AIT202         AIT203  \\\n",
       "count  449919.000000  449919.000000  449919.000000  449919.000000   \n",
       "mean        1.006946     210.297302       8.528535     320.301478   \n",
       "std         0.083051      35.157909       0.114844      16.631029   \n",
       "min         1.000000     168.033800       6.000000     285.337100   \n",
       "25%         1.000000     177.102000       8.441618     306.383000   \n",
       "50%         1.000000     193.508100       8.551525     321.661100   \n",
       "75%         1.000000     253.845200       8.610806     331.684200   \n",
       "max         2.000000     267.719800       8.733210     384.465500   \n",
       "\n",
       "0             FIT201          MV201           P201      P202           P203  \\\n",
       "count  449919.000000  449919.000000  449919.000000  449919.0  449919.000000   \n",
       "mean        1.702908       1.691584       1.121068       1.0       1.690689   \n",
       "std         1.130277       0.470611       0.326207       0.0       0.462210   \n",
       "min         0.000000       0.000000       1.000000       1.0       1.000000   \n",
       "25%         0.000000       1.000000       1.000000       1.0       1.000000   \n",
       "50%         2.446673       2.000000       1.000000       1.0       2.000000   \n",
       "75%         2.454362       2.000000       1.000000       1.0       2.000000   \n",
       "max         2.826899       2.000000       2.000000       1.0       2.000000   \n",
       "\n",
       "0               P204           P205           P206        DPIT301  \\\n",
       "count  449919.000000  449919.000000  449919.000000  449919.000000   \n",
       "mean        1.000124       1.691131       1.000122      15.827634   \n",
       "std         0.011156       0.462027       0.011056       7.740243   \n",
       "min         1.000000       1.000000       1.000000       0.000000   \n",
       "25%         1.000000       1.000000       1.000000      19.316220   \n",
       "50%         1.000000       2.000000       1.000000      19.898840   \n",
       "75%         1.000000       2.000000       1.000000      20.116530   \n",
       "max         2.000000       2.000000       2.000000      45.000000   \n",
       "\n",
       "0             FIT301         LIT301          MV301          MV302  \\\n",
       "count  449919.000000  449919.000000  449919.000000  449919.000000   \n",
       "mean        1.713555     910.076801       1.007321       1.749655   \n",
       "std         0.907519      80.522063       0.122666       0.448330   \n",
       "min         0.000000     364.386300       0.000000       0.000000   \n",
       "25%         2.194664     836.444200       1.000000       2.000000   \n",
       "50%         2.201582     924.682800       1.000000       2.000000   \n",
       "75%         2.207091     977.794200       1.000000       2.000000   \n",
       "max         2.376197    1201.000000       2.000000       2.000000   \n",
       "\n",
       "0              MV303          MV304      P301           P302         AIT401  \\\n",
       "count  449919.000000  449919.000000  449919.0  449919.000000  449919.000000   \n",
       "mean        1.023349       1.101163       1.0       1.772946     148.805855   \n",
       "std         0.181441       0.324082       0.0       0.418928       0.003889   \n",
       "min         0.000000       0.000000       1.0       1.000000     148.759900   \n",
       "25%         1.000000       1.000000       1.0       2.000000     148.803200   \n",
       "50%         1.000000       1.000000       1.0       2.000000     148.808000   \n",
       "75%         1.000000       1.000000       1.0       2.000000     148.808000   \n",
       "max         2.000000       2.000000       1.0       2.000000     148.856100   \n",
       "\n",
       "0             AIT402         FIT401         LIT401      P401           P402  \\\n",
       "count  449919.000000  449919.000000  449919.000000  449919.0  449919.000000   \n",
       "mean      161.990135       1.590214     833.542913       1.0       1.928792   \n",
       "std        44.740211       0.449035     186.068540       0.0       0.257173   \n",
       "min       140.835700       0.000000     243.014600       1.0       1.000000   \n",
       "25%       146.116400       1.710441     819.097700       1.0       2.000000   \n",
       "50%       150.166600       1.717361     884.427100       1.0       2.000000   \n",
       "75%       153.652900       1.724153     937.375100       1.0       2.000000   \n",
       "max       333.811800       1.744914    1002.781000       1.0       2.000000   \n",
       "\n",
       "0               P403      P404          UV401         AIT501         AIT502  \\\n",
       "count  449919.000000  449919.0  449919.000000  449919.000000  449919.000000   \n",
       "mean        1.000133       1.0       1.925849       7.787358     147.509939   \n",
       "std         0.011547       0.0       0.262017       0.084308      21.429151   \n",
       "min         1.000000       1.0       1.000000       7.432902     129.838500   \n",
       "25%         1.000000       1.0       2.000000       7.772879     138.990000   \n",
       "50%         1.000000       1.0       2.000000       7.797873     142.912100   \n",
       "75%         1.000000       1.0       2.000000       7.840810     144.706500   \n",
       "max         2.000000       1.0       2.000000       8.307037     272.853100   \n",
       "\n",
       "0             AIT503         AIT504         FIT501         FIT502  \\\n",
       "count  449919.000000  449919.000000  449919.000000  449919.000000   \n",
       "mean      264.789668      14.504030       1.603014       1.195462   \n",
       "std         6.542092       7.944618       0.444681       0.331968   \n",
       "min       244.873100       9.536016       0.000000       0.000000   \n",
       "25%       259.965400      13.035120       1.719559       1.272576   \n",
       "50%       264.387300      14.611640       1.726993       1.286410   \n",
       "75%       269.129700      15.419120       1.733145       1.300115   \n",
       "max       297.263500     442.463500       1.753653       1.360318   \n",
       "\n",
       "0             FIT503         FIT504           P501      P502         PIT501  \\\n",
       "count  449919.000000  449919.000000  449919.000000  449919.0  449919.000000   \n",
       "mean        0.679549       0.283806       1.925862       1.0     232.173817   \n",
       "std         0.189503       0.080924       0.261995       0.0      61.750930   \n",
       "min         0.000000       0.000000       1.000000       1.0       9.468726   \n",
       "25%         0.730660       0.306249       2.000000       1.0     248.029400   \n",
       "50%         0.732708       0.306633       2.000000       1.0     249.295100   \n",
       "75%         0.734885       0.308106       2.000000       1.0     250.881200   \n",
       "max         0.741542       0.311693       2.000000       1.0     254.341800   \n",
       "\n",
       "0             PIT502         PIT503         FIT601      P601           P602  \\\n",
       "count  449919.000000  449919.000000  449919.000000  449919.0  449919.000000   \n",
       "mean        1.013408     174.714484       0.016566       1.0       1.009099   \n",
       "std         0.412723      47.479809       0.159603       0.0       0.094956   \n",
       "min         0.000000       3.140220       0.000000       1.0       1.000000   \n",
       "25%         0.816967     186.698900       0.000000       1.0       1.000000   \n",
       "50%         0.961138     187.724300       0.000000       1.0       1.000000   \n",
       "75%         1.409669     189.118200       0.000128       1.0       1.000000   \n",
       "max         1.970333     191.986000       1.802710       1.0       2.000000   \n",
       "\n",
       "0          P603  \n",
       "count  449919.0  \n",
       "mean        1.0  \n",
       "std         0.0  \n",
       "min         1.0  \n",
       "25%         1.0  \n",
       "50%         1.0  \n",
       "75%         1.0  \n",
       "max         1.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Переименуем нашу целевую переменную\n",
    "df = df.rename(columns={'Normal/Attack':'target'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Уберем пустые пространства в написании значения целевой переменной\n",
    "df.target = df.target.apply(lambda x: 'Attack' if x == 'A ttack' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заменим значения таргета на 0 и 1\n",
    "df['target'].replace({'Normal':0, 'Attack':1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Переведем время в unixTime\n",
    "df['unixTime'] = df['Timestamp'].apply(lambda x: x.timestamp())\n",
    "s = pd.Series(df['unixTime'])\n",
    "# df['diff'] = s.diff().fillna(s)\n",
    "# df.style.format({'unixTime': '{:.2f}'}) -- у меня форматирование на таком количесве строк виснет правда"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим новые признаки из признака Timestamp\n",
    "df['day_sin'] = df['Timestamp'].apply(lambda x: np.sin(2 * np.pi * x.timetuple().tm_yday/365.0))\n",
    "df['day_cos'] = df['Timestamp'].apply(lambda x: np.cos(2 * np.pi * x.timetuple().tm_yday/365.0))\n",
    "\n",
    "df['month_sin'] = np.sin(2 * np.pi * df['Timestamp'].dt.month/12.0)\n",
    "df['month_cos'] = np.cos(2 * np.pi * df['Timestamp'].dt.month/12.0)\n",
    "\n",
    "df['hour_sin'] = df['Timestamp'].apply(lambda x: np.sin(2 * np.pi * x.hour/24.0))\n",
    "df['hour_cos'] = df['Timestamp'].apply(lambda x: np.cos(2 * np.pi * x.hour/24.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удалим колонку Timestamp\n",
    "df.drop('Timestamp', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер df_train: (269951, 59) , 60.0 % от датасета df\n",
      "Размер df_test: (179968, 59) , 40.0 % от датасета df\n"
     ]
    }
   ],
   "source": [
    "# разделим датасет на test и train\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(df,train_size=0.6,random_state=42)\n",
    "print('Размер df_train:', df_train.shape,',', round(len(df_train)/len(df)*100,2), '% от датасета df')\n",
    "print('Размер df_test:', df_test.shape,',', round(len(df_test)/len(df)*100,2), '% от датасета df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Установка lightautoml\n",
    "# !pip install -U lightautoml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard python libraries\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Essential DS libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "# LightAutoML presets, task and report generation\n",
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\n",
    "from lightautoml.tasks import Task\n",
    "from lightautoml.report.report_deco import ReportDeco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_THREADS = 4\n",
    "N_FOLDS = 5\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.3\n",
    "TIMEOUT = 900\n",
    "TARGET_NAME = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = Task('binary', loss = 'logloss', metric = 'auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "roles = {\n",
    "    'target': TARGET_NAME\n",
    "}\n",
    "# roles = {\n",
    "#     'target': TARGET_NAME,\n",
    "#     'drop': ['sell_id','Комплектация', 'start_date', 'model', 'HAS_OPTION_abs', 'HAS_OPTION_airbag-driver','HAS_OPTION_lock']\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = TabularAutoML(\n",
    "    task = task, \n",
    "    timeout = TIMEOUT,\n",
    "    cpu_limit = N_THREADS,\n",
    "    reader_params = {'n_jobs': N_THREADS, 'cv': N_FOLDS, 'random_state': RANDOM_STATE}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:52:32] Stdout logging level is INFO3.\n",
      "[09:52:32] Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n",
      "[09:52:32] Task: binary\n",
      "\n",
      "[09:52:32] Start automl preset with listed constraints:\n",
      "[09:52:32] - time: 900.00 seconds\n",
      "[09:52:32] - CPU: 4 cores\n",
      "[09:52:32] - memory: 16 GB\n",
      "\n",
      "[09:52:32] \u001b[1mTrain data shape: (269951, 59)\u001b[0m\n",
      "\n",
      "[09:52:40] Feats was rejected during automatic roles guess: []\n",
      "[09:52:40] Layer \u001b[1m1\u001b[0m train process start. Time left 892.13 secs\n",
      "[09:53:05] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[09:53:05] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "[09:53:06] Linear model: C = 1e-05 score = 0.999574365652411\n",
      "[09:53:07] Linear model: C = 5e-05 score = 0.9997876027934095\n",
      "[09:53:08] Linear model: C = 0.0001 score = 0.9998329270700401\n",
      "[09:53:09] Linear model: C = 0.0005 score = 0.9998972158427076\n",
      "[09:53:09] Linear model: C = 0.001 score = 0.9999092838658094\n",
      "[09:53:11] Linear model: C = 0.005 score = 0.9999256513232748\n",
      "[09:53:11] Linear model: C = 0.01 score = 0.9999256513232748\n",
      "[09:53:12] Linear model: C = 0.05 score = 0.9999319910580775\n",
      "[09:53:12] Linear model: C = 0.1 score = 0.9999319910580775\n",
      "[09:53:12] Linear model: C = 0.5 score = 0.9999319910580775\n",
      "[09:53:12] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "[09:53:13] Linear model: C = 1e-05 score = 0.9995237424061594\n",
      "[09:53:14] Linear model: C = 5e-05 score = 0.999753124573642\n",
      "[09:53:15] Linear model: C = 0.0001 score = 0.9998167182827236\n",
      "[09:53:16] Linear model: C = 0.0005 score = 0.9998889797647862\n",
      "[09:53:16] Linear model: C = 0.001 score = 0.9999033654355394\n",
      "[09:53:18] Linear model: C = 0.005 score = 0.9999222990317371\n",
      "[09:53:18] Linear model: C = 0.01 score = 0.9999222990317371\n",
      "[09:53:19] Linear model: C = 0.05 score = 0.9999318100860105\n",
      "[09:53:19] Linear model: C = 0.1 score = 0.9999318100860105\n",
      "[09:53:19] Linear model: C = 0.5 score = 0.9999318100860105\n",
      "[09:53:19] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "[09:53:21] Linear model: C = 1e-05 score = 0.9995511791511656\n",
      "[09:53:22] Linear model: C = 5e-05 score = 0.9997668440971641\n",
      "[09:53:22] Linear model: C = 0.0001 score = 0.9998186636715883\n",
      "[09:53:23] Linear model: C = 0.0005 score = 0.9998832048195874\n",
      "[09:53:24] Linear model: C = 0.001 score = 0.9998967727816898\n",
      "[09:53:25] Linear model: C = 0.005 score = 0.9999174980368934\n",
      "[09:53:25] Linear model: C = 0.01 score = 0.9999174980368934\n",
      "[09:53:27] Linear model: C = 0.05 score = 0.999929009564512\n",
      "[09:53:27] Linear model: C = 0.1 score = 0.999929009564512\n",
      "[09:53:27] Linear model: C = 0.5 score = 0.999929009564512\n",
      "[09:53:27] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "[09:53:28] Linear model: C = 1e-05 score = 0.9995591442143068\n",
      "[09:53:29] Linear model: C = 5e-05 score = 0.9997794305060309\n",
      "[09:53:30] Linear model: C = 0.0001 score = 0.9998334738617202\n",
      "[09:53:31] Linear model: C = 0.0005 score = 0.9998939729413128\n",
      "[09:53:32] Linear model: C = 0.001 score = 0.9999069423168518\n",
      "[09:53:33] Linear model: C = 0.005 score = 0.9999230880630253\n",
      "[09:53:33] Linear model: C = 0.01 score = 0.9999230880630253\n",
      "[09:53:34] Linear model: C = 0.05 score = 0.9999285300516202\n",
      "[09:53:34] Linear model: C = 0.1 score = 0.9999285300516202\n",
      "[09:53:34] Linear model: C = 0.5 score = 0.9999285300516202\n",
      "[09:53:35] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "[09:53:36] Linear model: C = 1e-05 score = 0.999600971254972\n",
      "[09:53:37] Linear model: C = 5e-05 score = 0.9997908680148809\n",
      "[09:53:37] Linear model: C = 0.0001 score = 0.9998447021870936\n",
      "[09:53:38] Linear model: C = 0.0005 score = 0.9999122362679093\n",
      "[09:53:39] Linear model: C = 0.001 score = 0.9999264317804409\n",
      "[09:53:40] Linear model: C = 0.005 score = 0.9999415026453664\n",
      "[09:53:40] Linear model: C = 0.01 score = 0.9999415026453664\n",
      "[09:53:42] Linear model: C = 0.05 score = 0.9999490107230669\n",
      "[09:53:42] Linear model: C = 0.1 score = 0.9999490107230669\n",
      "[09:53:42] Linear model: C = 0.5 score = 0.9999490107230669\n",
      "[09:53:42] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.9999323481178684\u001b[0m\n",
      "[09:53:42] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[09:53:42] Time left 830.40 secs\n",
      "\n",
      "[09:53:43] [1]\tvalid's auc: 0.99659\n",
      "[09:53:43] Training until validation scores don't improve for 100 rounds\n",
      "[09:53:46] [100]\tvalid's auc: 0.999995\n",
      "[09:53:48] [200]\tvalid's auc: 0.999998\n",
      "[09:53:51] [300]\tvalid's auc: 0.999999\n",
      "[09:53:53] [400]\tvalid's auc: 0.999999\n",
      "[09:53:55] [500]\tvalid's auc: 0.999999\n",
      "[09:53:57] [600]\tvalid's auc: 0.999999\n",
      "[09:53:58] [700]\tvalid's auc: 0.999999\n",
      "[09:54:00] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[09:54:24] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[09:54:24] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "[09:54:25] [1]\tvalid's auc: 0.999875\n",
      "[09:54:25] Training until validation scores don't improve for 100 rounds\n",
      "[09:54:27] [100]\tvalid's auc: 0.999986\n",
      "[09:54:29] [200]\tvalid's auc: 0.999991\n",
      "[09:54:31] [300]\tvalid's auc: 0.999992\n",
      "[09:54:33] [400]\tvalid's auc: 0.999993\n",
      "[09:54:35] [500]\tvalid's auc: 0.999993\n",
      "[09:54:36] [600]\tvalid's auc: 0.999993\n",
      "[09:54:38] [700]\tvalid's auc: 0.999993\n",
      "[09:54:39] [800]\tvalid's auc: 0.999993\n",
      "[09:54:40] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "[09:54:41] [1]\tvalid's auc: 0.999893\n",
      "[09:54:41] Training until validation scores don't improve for 100 rounds\n",
      "[09:54:43] [100]\tvalid's auc: 0.99999\n",
      "[09:54:45] [200]\tvalid's auc: 0.999994\n",
      "[09:54:47] [300]\tvalid's auc: 0.999995\n",
      "[09:54:49] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "[09:54:50] [1]\tvalid's auc: 0.999866\n",
      "[09:54:50] Training until validation scores don't improve for 100 rounds\n",
      "[09:54:52] [100]\tvalid's auc: 0.999989\n",
      "[09:54:54] [200]\tvalid's auc: 0.999994\n",
      "[09:54:56] [300]\tvalid's auc: 0.999995\n",
      "[09:54:58] [400]\tvalid's auc: 0.999995\n",
      "[09:55:00] [500]\tvalid's auc: 0.999996\n",
      "[09:55:02] [600]\tvalid's auc: 0.999996\n",
      "[09:55:03] [700]\tvalid's auc: 0.999996\n",
      "[09:55:04] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "[09:55:05] [1]\tvalid's auc: 0.999771\n",
      "[09:55:05] Training until validation scores don't improve for 100 rounds\n",
      "[09:55:07] [100]\tvalid's auc: 0.999989\n",
      "[09:55:09] [200]\tvalid's auc: 0.999992\n",
      "[09:55:11] [300]\tvalid's auc: 0.999993\n",
      "[09:55:14] [400]\tvalid's auc: 0.999993\n",
      "[09:55:15] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "[09:55:16] [1]\tvalid's auc: 0.999902\n",
      "[09:55:16] Training until validation scores don't improve for 100 rounds\n",
      "[09:55:18] [100]\tvalid's auc: 0.999993\n",
      "[09:55:21] [200]\tvalid's auc: 0.999997\n",
      "[09:55:23] [300]\tvalid's auc: 0.999997\n",
      "[09:55:26] [400]\tvalid's auc: 0.999997\n",
      "[09:55:28] [500]\tvalid's auc: 0.999997\n",
      "[09:55:30] [600]\tvalid's auc: 0.999997\n",
      "[09:55:31] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.9999945586635057\u001b[0m\n",
      "[09:55:31] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[09:55:31] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 1.00 secs\n",
      "[09:55:32] [1]\tvalid's auc: 0.999929\n",
      "[09:55:32] Training until validation scores don't improve for 100 rounds\n",
      "[09:55:36] [100]\tvalid's auc: 0.999993\n",
      "[09:55:39] [200]\tvalid's auc: 0.999995\n",
      "[09:55:40] \u001b[1mTrial 1\u001b[0m with hyperparameters {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07} scored 0.9999949056851813 in 0:00:09.268694\n",
      "[09:55:40] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[09:55:40] The set of hyperparameters \u001b[1m{'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07}\u001b[0m\n",
      " achieve 1.0000 auc\n",
      "[09:55:40] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:55:41] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
      "[09:55:41] [1]\tvalid's auc: 0.999929\n",
      "[09:55:41] Training until validation scores don't improve for 100 rounds\n",
      "[09:55:45] [100]\tvalid's auc: 0.999994\n",
      "[09:55:48] [200]\tvalid's auc: 0.999995\n",
      "[09:55:49] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
      "[09:55:50] [1]\tvalid's auc: 0.99991\n",
      "[09:55:50] Training until validation scores don't improve for 100 rounds\n",
      "[09:55:54] [100]\tvalid's auc: 0.999996\n",
      "[09:55:56] [200]\tvalid's auc: 0.999997\n",
      "[09:55:58] [300]\tvalid's auc: 0.999997\n",
      "[09:56:00] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
      "[09:56:01] [1]\tvalid's auc: 0.999926\n",
      "[09:56:01] Training until validation scores don't improve for 100 rounds\n",
      "[09:56:05] [100]\tvalid's auc: 0.999995\n",
      "[09:56:08] [200]\tvalid's auc: 0.999997\n",
      "[09:56:10] [300]\tvalid's auc: 0.999997\n",
      "[09:56:11] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
      "[09:56:12] [1]\tvalid's auc: 0.999844\n",
      "[09:56:12] Training until validation scores don't improve for 100 rounds\n",
      "[09:56:16] [100]\tvalid's auc: 0.999995\n",
      "[09:56:20] [200]\tvalid's auc: 0.999996\n",
      "[09:56:21] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
      "[09:56:22] [1]\tvalid's auc: 0.999949\n",
      "[09:56:22] Training until validation scores don't improve for 100 rounds\n",
      "[09:56:26] [100]\tvalid's auc: 0.999998\n",
      "[09:56:28] [200]\tvalid's auc: 0.999998\n",
      "[09:56:30] [300]\tvalid's auc: 0.999998\n",
      "[09:56:31] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.9999964559030253\u001b[0m\n",
      "[09:56:31] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[09:56:31] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[09:56:31] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "[09:56:32] 0:\ttest: 0.9897997\tbest: 0.9897997 (0)\ttotal: 198ms\tremaining: 6m 36s\n",
      "[09:56:35] 99:\ttest: 0.9999217\tbest: 0.9999217 (99)\ttotal: 3.17s\tremaining: 1m\n",
      "[09:56:38] 199:\ttest: 0.9999553\tbest: 0.9999553 (199)\ttotal: 6.27s\tremaining: 56.5s\n",
      "[09:56:41] 299:\ttest: 0.9999705\tbest: 0.9999705 (299)\ttotal: 9.31s\tremaining: 52.8s\n",
      "[09:56:44] 399:\ttest: 0.9999776\tbest: 0.9999776 (399)\ttotal: 12.4s\tremaining: 49.5s\n",
      "[09:56:47] 499:\ttest: 0.9999816\tbest: 0.9999816 (499)\ttotal: 15.5s\tremaining: 46.5s\n",
      "[09:56:51] 599:\ttest: 0.9999835\tbest: 0.9999835 (596)\ttotal: 18.6s\tremaining: 43.3s\n",
      "[09:56:54] 699:\ttest: 0.9999843\tbest: 0.9999846 (697)\ttotal: 21.7s\tremaining: 40.2s\n",
      "[09:56:57] 799:\ttest: 0.9999848\tbest: 0.9999849 (797)\ttotal: 24.7s\tremaining: 37.1s\n",
      "[09:57:00] 899:\ttest: 0.9999859\tbest: 0.9999859 (899)\ttotal: 27.8s\tremaining: 33.9s\n",
      "[09:57:03] 999:\ttest: 0.9999871\tbest: 0.9999871 (999)\ttotal: 30.8s\tremaining: 30.8s\n",
      "[09:57:06] 1099:\ttest: 0.9999870\tbest: 0.9999874 (1035)\ttotal: 33.7s\tremaining: 27.6s\n",
      "[09:57:07] Stopped by overfitting detector  (100 iterations wait)\n",
      "[09:57:07] bestTest = 0.9999873591\n",
      "[09:57:07] bestIteration = 1035\n",
      "[09:57:07] Shrink model to first 1036 iterations.\n",
      "[09:57:07] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "[09:57:08] 0:\ttest: 0.9911729\tbest: 0.9911729 (0)\ttotal: 41.9ms\tremaining: 1m 23s\n",
      "[09:57:10] bestTest = 0.999788676\n",
      "[09:57:10] bestIteration = 10\n",
      "[09:57:10] Shrink model to first 11 iterations.\n",
      "[09:57:10] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training has stopped (degenerate solution on iteration 66, probably too small l2-regularization, try to increase it)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:57:10] 0:\ttest: 0.9950980\tbest: 0.9950980 (0)\ttotal: 35.5ms\tremaining: 1m 10s\n",
      "[09:57:13] 99:\ttest: 0.9999154\tbest: 0.9999154 (99)\ttotal: 3.03s\tremaining: 57.6s\n",
      "[09:57:16] 199:\ttest: 0.9999545\tbest: 0.9999549 (198)\ttotal: 6.2s\tremaining: 55.8s\n",
      "[09:57:20] 299:\ttest: 0.9999699\tbest: 0.9999699 (299)\ttotal: 9.28s\tremaining: 52.6s\n",
      "[09:57:23] 399:\ttest: 0.9999760\tbest: 0.9999760 (399)\ttotal: 12.4s\tremaining: 49.5s\n",
      "[09:57:26] 499:\ttest: 0.9999801\tbest: 0.9999801 (499)\ttotal: 15.5s\tremaining: 46.4s\n",
      "[09:57:29] 599:\ttest: 0.9999816\tbest: 0.9999817 (589)\ttotal: 18.9s\tremaining: 44.1s\n",
      "[09:57:33] 699:\ttest: 0.9999833\tbest: 0.9999834 (695)\ttotal: 22.3s\tremaining: 41.4s\n",
      "[09:57:36] 799:\ttest: 0.9999847\tbest: 0.9999847 (796)\ttotal: 25.4s\tremaining: 38.1s\n",
      "[09:57:39] 899:\ttest: 0.9999858\tbest: 0.9999859 (895)\ttotal: 28.5s\tremaining: 34.8s\n",
      "[09:57:42] 999:\ttest: 0.9999867\tbest: 0.9999868 (969)\ttotal: 31.7s\tremaining: 31.7s\n",
      "[09:57:45] 1099:\ttest: 0.9999875\tbest: 0.9999875 (1099)\ttotal: 34.6s\tremaining: 28.3s\n",
      "[09:57:48] 1199:\ttest: 0.9999873\tbest: 0.9999875 (1109)\ttotal: 37.5s\tremaining: 25s\n",
      "[09:57:48] Stopped by overfitting detector  (100 iterations wait)\n",
      "[09:57:48] bestTest = 0.9999875198\n",
      "[09:57:48] bestIteration = 1109\n",
      "[09:57:48] Shrink model to first 1110 iterations.\n",
      "[09:57:48] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "[09:57:49] 0:\ttest: 0.9922259\tbest: 0.9922259 (0)\ttotal: 41.3ms\tremaining: 1m 22s\n",
      "[09:57:52] 99:\ttest: 0.9999111\tbest: 0.9999111 (99)\ttotal: 3.02s\tremaining: 57.5s\n",
      "[09:57:55] 199:\ttest: 0.9999486\tbest: 0.9999486 (199)\ttotal: 6.09s\tremaining: 54.8s\n",
      "[09:57:58] 299:\ttest: 0.9999590\tbest: 0.9999593 (296)\ttotal: 9.3s\tremaining: 52.7s\n",
      "[09:58:01] 399:\ttest: 0.9999650\tbest: 0.9999650 (399)\ttotal: 12.4s\tremaining: 49.7s\n",
      "[09:58:04] 499:\ttest: 0.9999670\tbest: 0.9999670 (499)\ttotal: 15.5s\tremaining: 46.5s\n",
      "[09:58:08] 599:\ttest: 0.9999680\tbest: 0.9999680 (599)\ttotal: 18.7s\tremaining: 43.5s\n",
      "[09:58:11] 699:\ttest: 0.9999679\tbest: 0.9999681 (603)\ttotal: 21.8s\tremaining: 40.5s\n",
      "[09:58:11] Stopped by overfitting detector  (100 iterations wait)\n",
      "[09:58:11] bestTest = 0.9999681043\n",
      "[09:58:11] bestIteration = 603\n",
      "[09:58:11] Shrink model to first 604 iterations.\n",
      "[09:58:11] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "[09:58:12] 0:\ttest: 0.9960766\tbest: 0.9960766 (0)\ttotal: 32.7ms\tremaining: 1m 5s\n",
      "[09:58:14] 99:\ttest: 0.9999443\tbest: 0.9999443 (99)\ttotal: 2.98s\tremaining: 56.5s\n",
      "[09:58:18] 199:\ttest: 0.9999727\tbest: 0.9999727 (199)\ttotal: 6.11s\tremaining: 55s\n",
      "[09:58:21] 299:\ttest: 0.9999842\tbest: 0.9999842 (299)\ttotal: 9.15s\tremaining: 51.9s\n",
      "[09:58:24] 399:\ttest: 0.9999891\tbest: 0.9999891 (399)\ttotal: 12.2s\tremaining: 49s\n",
      "[09:58:27] 499:\ttest: 0.9999912\tbest: 0.9999912 (497)\ttotal: 15.3s\tremaining: 46s\n",
      "[09:58:30] 599:\ttest: 0.9999926\tbest: 0.9999926 (595)\ttotal: 18.4s\tremaining: 43s\n",
      "[09:58:33] 699:\ttest: 0.9999936\tbest: 0.9999936 (697)\ttotal: 21.5s\tremaining: 39.9s\n",
      "[09:58:36] 799:\ttest: 0.9999950\tbest: 0.9999950 (799)\ttotal: 24.5s\tremaining: 36.8s\n",
      "[09:58:39] 899:\ttest: 0.9999959\tbest: 0.9999959 (893)\ttotal: 27.6s\tremaining: 33.7s\n",
      "[09:58:42] 999:\ttest: 0.9999960\tbest: 0.9999960 (934)\ttotal: 30.6s\tremaining: 30.6s\n",
      "[09:58:45] 1099:\ttest: 0.9999964\tbest: 0.9999964 (1098)\ttotal: 33.5s\tremaining: 27.4s\n",
      "[09:58:48] 1199:\ttest: 0.9999966\tbest: 0.9999966 (1197)\ttotal: 36.4s\tremaining: 24.3s\n",
      "[09:58:51] 1299:\ttest: 0.9999965\tbest: 0.9999967 (1260)\ttotal: 39.2s\tremaining: 21.1s\n",
      "[09:58:53] Stopped by overfitting detector  (100 iterations wait)\n",
      "[09:58:53] bestTest = 0.9999966531\n",
      "[09:58:53] bestIteration = 1260\n",
      "[09:58:53] Shrink model to first 1261 iterations.\n",
      "[09:58:53] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.9997940653863284\u001b[0m\n",
      "[09:58:53] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[09:58:53] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 1.00 secs\n",
      "[09:58:54] 0:\ttest: 0.9889158\tbest: 0.9889158 (0)\ttotal: 29.6ms\tremaining: 59.1s\n",
      "[09:58:57] 99:\ttest: 0.9998915\tbest: 0.9998917 (98)\ttotal: 2.87s\tremaining: 54.6s\n",
      "[09:59:00] 199:\ttest: 0.9999230\tbest: 0.9999230 (199)\ttotal: 5.71s\tremaining: 51.4s\n",
      "[09:59:02] 299:\ttest: 0.9999445\tbest: 0.9999445 (299)\ttotal: 8.59s\tremaining: 48.7s\n",
      "[09:59:05] 399:\ttest: 0.9999562\tbest: 0.9999562 (399)\ttotal: 11.5s\tremaining: 45.9s\n",
      "[09:59:08] 499:\ttest: 0.9999641\tbest: 0.9999641 (499)\ttotal: 14.4s\tremaining: 43.1s\n",
      "[09:59:11] 599:\ttest: 0.9999688\tbest: 0.9999688 (598)\ttotal: 17.3s\tremaining: 40.3s\n",
      "[09:59:14] 699:\ttest: 0.9999720\tbest: 0.9999720 (697)\ttotal: 20.1s\tremaining: 37.3s\n",
      "[09:59:17] 799:\ttest: 0.9999744\tbest: 0.9999744 (799)\ttotal: 22.9s\tremaining: 34.3s\n",
      "[09:59:20] 899:\ttest: 0.9999767\tbest: 0.9999767 (896)\ttotal: 25.7s\tremaining: 31.4s\n",
      "[09:59:22] 999:\ttest: 0.9999779\tbest: 0.9999780 (988)\ttotal: 28.5s\tremaining: 28.5s\n",
      "[09:59:25] 1099:\ttest: 0.9999793\tbest: 0.9999793 (1099)\ttotal: 31.2s\tremaining: 25.6s\n",
      "[09:59:28] 1199:\ttest: 0.9999804\tbest: 0.9999804 (1199)\ttotal: 34s\tremaining: 22.7s\n",
      "[09:59:31] 1299:\ttest: 0.9999812\tbest: 0.9999812 (1293)\ttotal: 36.7s\tremaining: 19.8s\n",
      "[09:59:33] 1399:\ttest: 0.9999815\tbest: 0.9999815 (1376)\ttotal: 39.4s\tremaining: 16.9s\n",
      "[09:59:36] 1499:\ttest: 0.9999820\tbest: 0.9999821 (1489)\ttotal: 42s\tremaining: 14s\n",
      "[09:59:39] 1599:\ttest: 0.9999821\tbest: 0.9999824 (1555)\ttotal: 44.7s\tremaining: 11.2s\n",
      "[09:59:40] Stopped by overfitting detector  (100 iterations wait)\n",
      "[09:59:40] bestTest = 0.9999823968\n",
      "[09:59:40] bestIteration = 1555\n",
      "[09:59:40] Shrink model to first 1556 iterations.\n",
      "[09:59:40] \u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 3.6010467344475403, 'min_data_in_leaf': 15} scored 0.999982396776969 in 0:00:47.349861\n",
      "[09:59:40] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[09:59:40] The set of hyperparameters \u001b[1m{'max_depth': 4, 'l2_leaf_reg': 3.6010467344475403, 'min_data_in_leaf': 15}\u001b[0m\n",
      " achieve 1.0000 auc\n",
      "[09:59:40] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[09:59:40] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "[09:59:41] 0:\ttest: 0.9889158\tbest: 0.9889158 (0)\ttotal: 36ms\tremaining: 1m 48s\n",
      "[09:59:44] 99:\ttest: 0.9998711\tbest: 0.9998711 (99)\ttotal: 2.81s\tremaining: 1m 21s\n",
      "[09:59:46] 199:\ttest: 0.9999024\tbest: 0.9999024 (199)\ttotal: 5.62s\tremaining: 1m 18s\n",
      "[09:59:49] 299:\ttest: 0.9999245\tbest: 0.9999245 (299)\ttotal: 8.44s\tremaining: 1m 15s\n",
      "[09:59:52] 399:\ttest: 0.9999366\tbest: 0.9999366 (399)\ttotal: 11.3s\tremaining: 1m 13s\n",
      "[09:59:55] 499:\ttest: 0.9999460\tbest: 0.9999460 (499)\ttotal: 14.1s\tremaining: 1m 10s\n",
      "[09:59:58] 599:\ttest: 0.9999534\tbest: 0.9999534 (599)\ttotal: 17s\tremaining: 1m 8s\n",
      "[10:00:01] 699:\ttest: 0.9999584\tbest: 0.9999584 (699)\ttotal: 19.9s\tremaining: 1m 5s\n",
      "[10:00:04] 799:\ttest: 0.9999626\tbest: 0.9999626 (798)\ttotal: 22.7s\tremaining: 1m 2s\n",
      "[10:00:07] 899:\ttest: 0.9999667\tbest: 0.9999668 (898)\ttotal: 25.5s\tremaining: 59.6s\n",
      "[10:00:09] 999:\ttest: 0.9999690\tbest: 0.9999690 (996)\ttotal: 28.4s\tremaining: 56.8s\n",
      "[10:00:12] 1099:\ttest: 0.9999713\tbest: 0.9999713 (1098)\ttotal: 31.2s\tremaining: 54s\n",
      "[10:00:15] 1199:\ttest: 0.9999731\tbest: 0.9999731 (1198)\ttotal: 34s\tremaining: 51.1s\n",
      "[10:00:18] 1299:\ttest: 0.9999745\tbest: 0.9999746 (1297)\ttotal: 36.9s\tremaining: 48.2s\n",
      "[10:00:21] 1399:\ttest: 0.9999762\tbest: 0.9999762 (1399)\ttotal: 39.9s\tremaining: 45.6s\n",
      "[10:00:24] 1499:\ttest: 0.9999773\tbest: 0.9999773 (1495)\ttotal: 42.6s\tremaining: 42.6s\n",
      "[10:00:26] 1599:\ttest: 0.9999780\tbest: 0.9999781 (1595)\ttotal: 45.4s\tremaining: 39.7s\n",
      "[10:00:29] 1699:\ttest: 0.9999789\tbest: 0.9999790 (1690)\ttotal: 48.2s\tremaining: 36.8s\n",
      "[10:00:32] 1799:\ttest: 0.9999794\tbest: 0.9999794 (1799)\ttotal: 50.8s\tremaining: 33.9s\n",
      "[10:00:35] 1899:\ttest: 0.9999800\tbest: 0.9999800 (1898)\ttotal: 53.6s\tremaining: 31s\n",
      "[10:00:37] 1999:\ttest: 0.9999805\tbest: 0.9999805 (1999)\ttotal: 56.3s\tremaining: 28.1s\n",
      "[10:00:40] 2099:\ttest: 0.9999807\tbest: 0.9999807 (2078)\ttotal: 59s\tremaining: 25.3s\n",
      "[10:00:43] 2199:\ttest: 0.9999811\tbest: 0.9999811 (2199)\ttotal: 1m 1s\tremaining: 22.4s\n",
      "[10:00:45] 2299:\ttest: 0.9999813\tbest: 0.9999813 (2297)\ttotal: 1m 4s\tremaining: 19.6s\n",
      "[10:00:48] 2399:\ttest: 0.9999813\tbest: 0.9999814 (2370)\ttotal: 1m 6s\tremaining: 16.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:00:51] 2499:\ttest: 0.9999815\tbest: 0.9999815 (2492)\ttotal: 1m 9s\tremaining: 13.9s\n",
      "[10:00:53] 2599:\ttest: 0.9999815\tbest: 0.9999816 (2523)\ttotal: 1m 12s\tremaining: 11.1s\n",
      "[10:00:56] 2699:\ttest: 0.9999817\tbest: 0.9999817 (2682)\ttotal: 1m 14s\tremaining: 8.3s\n",
      "[10:00:59] 2799:\ttest: 0.9999820\tbest: 0.9999820 (2780)\ttotal: 1m 17s\tremaining: 5.52s\n",
      "[10:01:01] 2899:\ttest: 0.9999820\tbest: 0.9999821 (2869)\ttotal: 1m 19s\tremaining: 2.75s\n",
      "[10:01:04] 2999:\ttest: 0.9999821\tbest: 0.9999822 (2989)\ttotal: 1m 22s\tremaining: 0us\n",
      "[10:01:04] bestTest = 0.9999821522\n",
      "[10:01:04] bestIteration = 2989\n",
      "[10:01:04] Shrink model to first 2990 iterations.\n",
      "[10:01:04] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "[10:01:04] 0:\ttest: 0.9910120\tbest: 0.9910120 (0)\ttotal: 38.9ms\tremaining: 1m 56s\n",
      "[10:01:07] 99:\ttest: 0.9998570\tbest: 0.9998570 (99)\ttotal: 2.75s\tremaining: 1m 19s\n",
      "[10:01:10] 199:\ttest: 0.9999048\tbest: 0.9999048 (199)\ttotal: 5.62s\tremaining: 1m 18s\n",
      "[10:01:13] 299:\ttest: 0.9999334\tbest: 0.9999334 (299)\ttotal: 8.46s\tremaining: 1m 16s\n",
      "[10:01:16] 399:\ttest: 0.9999491\tbest: 0.9999491 (399)\ttotal: 11.3s\tremaining: 1m 13s\n",
      "[10:01:19] 499:\ttest: 0.9999596\tbest: 0.9999596 (499)\ttotal: 14.1s\tremaining: 1m 10s\n",
      "[10:01:21] 599:\ttest: 0.9999672\tbest: 0.9999672 (599)\ttotal: 16.9s\tremaining: 1m 7s\n",
      "[10:01:24] 699:\ttest: 0.9999727\tbest: 0.9999727 (699)\ttotal: 19.7s\tremaining: 1m 4s\n",
      "[10:01:27] 799:\ttest: 0.9999766\tbest: 0.9999766 (799)\ttotal: 22.5s\tremaining: 1m 1s\n",
      "[10:01:30] 899:\ttest: 0.9999794\tbest: 0.9999794 (899)\ttotal: 25.3s\tremaining: 59.1s\n",
      "[10:01:33] 999:\ttest: 0.9999815\tbest: 0.9999815 (998)\ttotal: 28.1s\tremaining: 56.2s\n",
      "[10:01:36] 1099:\ttest: 0.9999830\tbest: 0.9999831 (1097)\ttotal: 31s\tremaining: 53.6s\n",
      "[10:01:39] 1199:\ttest: 0.9999847\tbest: 0.9999847 (1198)\ttotal: 34.1s\tremaining: 51.1s\n",
      "[10:01:41] 1299:\ttest: 0.9999861\tbest: 0.9999861 (1299)\ttotal: 36.8s\tremaining: 48.2s\n",
      "[10:01:44] 1399:\ttest: 0.9999867\tbest: 0.9999867 (1399)\ttotal: 39.6s\tremaining: 45.3s\n",
      "[10:01:47] 1499:\ttest: 0.9999874\tbest: 0.9999874 (1498)\ttotal: 42.4s\tremaining: 42.4s\n",
      "[10:01:50] 1599:\ttest: 0.9999885\tbest: 0.9999885 (1598)\ttotal: 45.1s\tremaining: 39.4s\n",
      "[10:01:52] 1699:\ttest: 0.9999892\tbest: 0.9999892 (1696)\ttotal: 47.9s\tremaining: 36.6s\n",
      "[10:01:55] 1799:\ttest: 0.9999897\tbest: 0.9999897 (1795)\ttotal: 50.6s\tremaining: 33.7s\n",
      "[10:01:58] 1899:\ttest: 0.9999901\tbest: 0.9999901 (1898)\ttotal: 53.3s\tremaining: 30.9s\n",
      "[10:02:01] 1999:\ttest: 0.9999905\tbest: 0.9999905 (1999)\ttotal: 56s\tremaining: 28s\n",
      "[10:02:03] 2099:\ttest: 0.9999908\tbest: 0.9999908 (2099)\ttotal: 58.7s\tremaining: 25.1s\n",
      "[10:02:06] 2199:\ttest: 0.9999912\tbest: 0.9999912 (2197)\ttotal: 1m 1s\tremaining: 22.4s\n",
      "[10:02:10] 2299:\ttest: 0.9999913\tbest: 0.9999913 (2299)\ttotal: 1m 4s\tremaining: 19.7s\n",
      "[10:02:12] 2399:\ttest: 0.9999916\tbest: 0.9999916 (2387)\ttotal: 1m 7s\tremaining: 16.9s\n",
      "[10:02:15] 2499:\ttest: 0.9999917\tbest: 0.9999918 (2468)\ttotal: 1m 10s\tremaining: 14s\n",
      "[10:02:17] 2599:\ttest: 0.9999920\tbest: 0.9999920 (2596)\ttotal: 1m 12s\tremaining: 11.2s\n",
      "[10:02:20] 2699:\ttest: 0.9999922\tbest: 0.9999922 (2682)\ttotal: 1m 15s\tremaining: 8.37s\n",
      "[10:02:23] 2799:\ttest: 0.9999923\tbest: 0.9999924 (2784)\ttotal: 1m 17s\tremaining: 5.56s\n",
      "[10:02:25] 2899:\ttest: 0.9999926\tbest: 0.9999926 (2889)\ttotal: 1m 20s\tremaining: 2.77s\n",
      "[10:02:28] 2999:\ttest: 0.9999926\tbest: 0.9999926 (2960)\ttotal: 1m 22s\tremaining: 0us\n",
      "[10:02:28] bestTest = 0.99999261\n",
      "[10:02:28] bestIteration = 2960\n",
      "[10:02:28] Shrink model to first 2961 iterations.\n",
      "[10:02:28] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "[10:02:28] 0:\ttest: 0.9950246\tbest: 0.9950246 (0)\ttotal: 28.8ms\tremaining: 1m 26s\n",
      "[10:02:31] 99:\ttest: 0.9998543\tbest: 0.9998543 (99)\ttotal: 2.75s\tremaining: 1m 19s\n",
      "[10:02:34] 199:\ttest: 0.9998983\tbest: 0.9998983 (199)\ttotal: 5.53s\tremaining: 1m 17s\n",
      "[10:02:37] 299:\ttest: 0.9999241\tbest: 0.9999241 (299)\ttotal: 8.36s\tremaining: 1m 15s\n",
      "[10:02:40] 399:\ttest: 0.9999414\tbest: 0.9999414 (399)\ttotal: 11.2s\tremaining: 1m 12s\n",
      "[10:02:42] 499:\ttest: 0.9999508\tbest: 0.9999508 (499)\ttotal: 14s\tremaining: 1m 10s\n",
      "[10:02:45] 599:\ttest: 0.9999572\tbest: 0.9999572 (599)\ttotal: 16.9s\tremaining: 1m 7s\n",
      "[10:02:48] 699:\ttest: 0.9999611\tbest: 0.9999611 (699)\ttotal: 19.7s\tremaining: 1m 4s\n",
      "[10:02:51] 799:\ttest: 0.9999653\tbest: 0.9999653 (797)\ttotal: 22.5s\tremaining: 1m 2s\n",
      "[10:02:54] 899:\ttest: 0.9999678\tbest: 0.9999679 (897)\ttotal: 25.4s\tremaining: 59.3s\n",
      "[10:02:57] 999:\ttest: 0.9999705\tbest: 0.9999705 (999)\ttotal: 28.2s\tremaining: 56.5s\n",
      "[10:03:00] 1099:\ttest: 0.9999728\tbest: 0.9999728 (1098)\ttotal: 31.1s\tremaining: 53.7s\n",
      "[10:03:02] 1199:\ttest: 0.9999743\tbest: 0.9999743 (1192)\ttotal: 33.9s\tremaining: 50.8s\n",
      "[10:03:05] 1299:\ttest: 0.9999759\tbest: 0.9999759 (1298)\ttotal: 36.7s\tremaining: 47.9s\n",
      "[10:03:08] 1399:\ttest: 0.9999771\tbest: 0.9999771 (1398)\ttotal: 39.4s\tremaining: 45.1s\n",
      "[10:03:11] 1499:\ttest: 0.9999778\tbest: 0.9999778 (1498)\ttotal: 42.2s\tremaining: 42.2s\n",
      "[10:03:14] 1599:\ttest: 0.9999788\tbest: 0.9999788 (1599)\ttotal: 45s\tremaining: 39.4s\n",
      "[10:03:17] 1699:\ttest: 0.9999796\tbest: 0.9999796 (1699)\ttotal: 47.9s\tremaining: 36.6s\n",
      "[10:03:20] 1799:\ttest: 0.9999802\tbest: 0.9999802 (1799)\ttotal: 51.3s\tremaining: 34.2s\n",
      "[10:03:23] 1899:\ttest: 0.9999809\tbest: 0.9999809 (1899)\ttotal: 54s\tremaining: 31.3s\n",
      "[10:03:25] 1999:\ttest: 0.9999813\tbest: 0.9999813 (1993)\ttotal: 56.7s\tremaining: 28.3s\n",
      "[10:03:28] 2099:\ttest: 0.9999815\tbest: 0.9999815 (2091)\ttotal: 59.3s\tremaining: 25.4s\n",
      "[10:03:31] 2199:\ttest: 0.9999819\tbest: 0.9999819 (2172)\ttotal: 1m 2s\tremaining: 22.6s\n",
      "[10:03:33] 2299:\ttest: 0.9999825\tbest: 0.9999825 (2297)\ttotal: 1m 4s\tremaining: 19.7s\n",
      "[10:03:36] 2399:\ttest: 0.9999828\tbest: 0.9999828 (2389)\ttotal: 1m 7s\tremaining: 16.8s\n",
      "[10:03:39] 2499:\ttest: 0.9999832\tbest: 0.9999832 (2498)\ttotal: 1m 9s\tremaining: 14s\n",
      "[10:03:41] 2599:\ttest: 0.9999835\tbest: 0.9999835 (2595)\ttotal: 1m 12s\tremaining: 11.1s\n",
      "[10:03:44] 2699:\ttest: 0.9999836\tbest: 0.9999836 (2697)\ttotal: 1m 14s\tremaining: 8.33s\n",
      "[10:03:46] 2799:\ttest: 0.9999837\tbest: 0.9999838 (2790)\ttotal: 1m 17s\tremaining: 5.54s\n",
      "[10:03:49] 2899:\ttest: 0.9999842\tbest: 0.9999842 (2894)\ttotal: 1m 20s\tremaining: 2.76s\n",
      "[10:03:51] 2999:\ttest: 0.9999844\tbest: 0.9999845 (2994)\ttotal: 1m 22s\tremaining: 0us\n",
      "[10:03:51] bestTest = 0.9999845172\n",
      "[10:03:51] bestIteration = 2994\n",
      "[10:03:51] Shrink model to first 2995 iterations.\n",
      "[10:03:52] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "[10:03:52] 0:\ttest: 0.9920914\tbest: 0.9920914 (0)\ttotal: 27.3ms\tremaining: 1m 21s\n",
      "[10:03:55] 99:\ttest: 0.9998631\tbest: 0.9998631 (99)\ttotal: 2.73s\tremaining: 1m 19s\n",
      "[10:03:58] 199:\ttest: 0.9998944\tbest: 0.9998944 (199)\ttotal: 5.57s\tremaining: 1m 17s\n",
      "[10:04:01] 299:\ttest: 0.9999208\tbest: 0.9999208 (299)\ttotal: 8.39s\tremaining: 1m 15s\n",
      "[10:04:03] 399:\ttest: 0.9999355\tbest: 0.9999355 (399)\ttotal: 11.2s\tremaining: 1m 13s\n",
      "[10:04:06] 499:\ttest: 0.9999433\tbest: 0.9999433 (499)\ttotal: 14.1s\tremaining: 1m 10s\n",
      "[10:04:09] 599:\ttest: 0.9999505\tbest: 0.9999505 (599)\ttotal: 17s\tremaining: 1m 7s\n",
      "[10:04:12] 699:\ttest: 0.9999555\tbest: 0.9999555 (699)\ttotal: 19.8s\tremaining: 1m 5s\n",
      "[10:04:15] 799:\ttest: 0.9999598\tbest: 0.9999598 (797)\ttotal: 22.6s\tremaining: 1m 2s\n",
      "[10:04:18] 899:\ttest: 0.9999627\tbest: 0.9999627 (897)\ttotal: 25.4s\tremaining: 59.4s\n",
      "[10:04:20] 999:\ttest: 0.9999645\tbest: 0.9999645 (995)\ttotal: 28.2s\tremaining: 56.5s\n",
      "[10:04:23] 1099:\ttest: 0.9999659\tbest: 0.9999659 (1099)\ttotal: 31s\tremaining: 53.6s\n",
      "[10:04:26] 1199:\ttest: 0.9999670\tbest: 0.9999670 (1199)\ttotal: 33.9s\tremaining: 50.8s\n",
      "[10:04:29] 1299:\ttest: 0.9999683\tbest: 0.9999683 (1299)\ttotal: 36.7s\tremaining: 48s\n",
      "[10:04:32] 1399:\ttest: 0.9999686\tbest: 0.9999686 (1399)\ttotal: 39.5s\tremaining: 45.2s\n",
      "[10:04:35] 1499:\ttest: 0.9999691\tbest: 0.9999691 (1491)\ttotal: 42.3s\tremaining: 42.3s\n",
      "[10:04:37] 1599:\ttest: 0.9999695\tbest: 0.9999695 (1599)\ttotal: 45.1s\tremaining: 39.4s\n",
      "[10:04:40] 1699:\ttest: 0.9999702\tbest: 0.9999702 (1699)\ttotal: 47.8s\tremaining: 36.6s\n",
      "[10:04:43] 1799:\ttest: 0.9999709\tbest: 0.9999709 (1785)\ttotal: 50.6s\tremaining: 33.7s\n",
      "[10:04:46] 1899:\ttest: 0.9999717\tbest: 0.9999717 (1899)\ttotal: 53.3s\tremaining: 30.9s\n",
      "[10:04:48] 1999:\ttest: 0.9999719\tbest: 0.9999719 (1999)\ttotal: 56s\tremaining: 28s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:04:51] 2099:\ttest: 0.9999723\tbest: 0.9999723 (2016)\ttotal: 58.6s\tremaining: 25.1s\n",
      "[10:04:54] 2199:\ttest: 0.9999727\tbest: 0.9999727 (2197)\ttotal: 1m 1s\tremaining: 22.2s\n",
      "[10:04:56] 2299:\ttest: 0.9999726\tbest: 0.9999728 (2216)\ttotal: 1m 3s\tremaining: 19.4s\n",
      "[10:04:57] Stopped by overfitting detector  (100 iterations wait)\n",
      "[10:04:57] bestTest = 0.9999728415\n",
      "[10:04:57] bestIteration = 2216\n",
      "[10:04:57] Shrink model to first 2217 iterations.\n",
      "[10:04:57] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "[10:04:57] 0:\ttest: 0.9960617\tbest: 0.9960617 (0)\ttotal: 38.9ms\tremaining: 1m 56s\n",
      "[10:05:00] 99:\ttest: 0.9998975\tbest: 0.9998975 (99)\ttotal: 2.73s\tremaining: 1m 19s\n",
      "[10:05:03] 199:\ttest: 0.9999336\tbest: 0.9999336 (199)\ttotal: 5.5s\tremaining: 1m 17s\n",
      "[10:05:06] 299:\ttest: 0.9999507\tbest: 0.9999507 (299)\ttotal: 8.3s\tremaining: 1m 14s\n",
      "[10:05:08] 399:\ttest: 0.9999621\tbest: 0.9999621 (399)\ttotal: 11.1s\tremaining: 1m 12s\n",
      "[10:05:11] 499:\ttest: 0.9999694\tbest: 0.9999694 (499)\ttotal: 14s\tremaining: 1m 9s\n",
      "[10:05:14] 599:\ttest: 0.9999740\tbest: 0.9999740 (599)\ttotal: 16.8s\tremaining: 1m 7s\n",
      "[10:05:17] 699:\ttest: 0.9999775\tbest: 0.9999775 (699)\ttotal: 19.6s\tremaining: 1m 4s\n",
      "[10:05:20] 799:\ttest: 0.9999795\tbest: 0.9999795 (798)\ttotal: 22.6s\tremaining: 1m 2s\n",
      "[10:05:23] 899:\ttest: 0.9999815\tbest: 0.9999815 (899)\ttotal: 25.4s\tremaining: 59.2s\n",
      "[10:05:26] 999:\ttest: 0.9999831\tbest: 0.9999831 (992)\ttotal: 28.2s\tremaining: 56.3s\n",
      "[10:05:28] 1099:\ttest: 0.9999848\tbest: 0.9999848 (1099)\ttotal: 31s\tremaining: 53.6s\n",
      "[10:05:31] 1199:\ttest: 0.9999859\tbest: 0.9999859 (1196)\ttotal: 33.8s\tremaining: 50.7s\n",
      "[10:05:34] 1299:\ttest: 0.9999868\tbest: 0.9999868 (1299)\ttotal: 36.6s\tremaining: 47.8s\n",
      "[10:05:37] 1399:\ttest: 0.9999877\tbest: 0.9999877 (1394)\ttotal: 39.4s\tremaining: 45s\n",
      "[10:05:40] 1499:\ttest: 0.9999886\tbest: 0.9999886 (1497)\ttotal: 42.3s\tremaining: 42.3s\n",
      "[10:05:43] 1599:\ttest: 0.9999892\tbest: 0.9999892 (1598)\ttotal: 45.1s\tremaining: 39.4s\n",
      "[10:05:45] 1699:\ttest: 0.9999896\tbest: 0.9999896 (1699)\ttotal: 47.8s\tremaining: 36.5s\n",
      "[10:05:48] 1799:\ttest: 0.9999902\tbest: 0.9999902 (1794)\ttotal: 50.4s\tremaining: 33.6s\n",
      "[10:05:51] 1899:\ttest: 0.9999906\tbest: 0.9999907 (1894)\ttotal: 53.1s\tremaining: 30.7s\n",
      "[10:05:53] 1999:\ttest: 0.9999912\tbest: 0.9999912 (1999)\ttotal: 55.8s\tremaining: 27.9s\n",
      "[10:05:56] 2099:\ttest: 0.9999916\tbest: 0.9999916 (2099)\ttotal: 58.4s\tremaining: 25s\n",
      "[10:05:59] 2199:\ttest: 0.9999919\tbest: 0.9999919 (2197)\ttotal: 1m\tremaining: 22.2s\n",
      "[10:06:01] 2299:\ttest: 0.9999921\tbest: 0.9999921 (2290)\ttotal: 1m 3s\tremaining: 19.3s\n",
      "[10:06:04] 2399:\ttest: 0.9999925\tbest: 0.9999925 (2398)\ttotal: 1m 6s\tremaining: 16.5s\n",
      "[10:06:06] 2499:\ttest: 0.9999928\tbest: 0.9999928 (2499)\ttotal: 1m 8s\tremaining: 13.7s\n",
      "[10:06:09] 2599:\ttest: 0.9999929\tbest: 0.9999930 (2590)\ttotal: 1m 11s\tremaining: 11s\n",
      "[10:06:11] 2699:\ttest: 0.9999932\tbest: 0.9999932 (2696)\ttotal: 1m 13s\tremaining: 8.2s\n",
      "[10:06:14] 2799:\ttest: 0.9999934\tbest: 0.9999934 (2789)\ttotal: 1m 16s\tremaining: 5.45s\n",
      "[10:06:17] 2899:\ttest: 0.9999935\tbest: 0.9999935 (2899)\ttotal: 1m 18s\tremaining: 2.72s\n",
      "[10:06:19] 2999:\ttest: 0.9999936\tbest: 0.9999936 (2978)\ttotal: 1m 21s\tremaining: 0us\n",
      "[10:06:19] bestTest = 0.9999936312\n",
      "[10:06:19] bestIteration = 2978\n",
      "[10:06:19] Shrink model to first 2979 iterations.\n",
      "[10:06:19] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.9999842962171427\u001b[0m\n",
      "[10:06:19] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[10:06:19] Time left 72.98 secs\n",
      "\n",
      "[10:06:19] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[10:06:19] Blending: optimization starts with equal weights and score \u001b[1m0.999977443858639\u001b[0m\n",
      "[10:06:23] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.9999964559030253\u001b[0m, weights = \u001b[1m[0. 0. 1. 0. 0.]\u001b[0m\n",
      "[10:06:25] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.9999964559030253\u001b[0m, weights = \u001b[1m[0. 0. 1. 0. 0.]\u001b[0m\n",
      "[10:06:25] Blending: no score update. Terminated\n",
      "\n",
      "[10:06:25] \u001b[1mAutoml preset training completed in 833.00 seconds\u001b[0m\n",
      "\n",
      "[10:06:25] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# обучение модели\n",
    "oof_pred = automl.fit_predict(df_train, roles = roles, verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9994850917388711"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(df_train[TARGET_NAME], (oof_pred.data[:,0] > 0.5).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.998601583150629"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(df_train[TARGET_NAME], (oof_pred.data[:,0] > 0.5).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9978768577494691"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(df_train[TARGET_NAME], (oof_pred.data[:,0] > 0.5).astype(int))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Feature'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABsQAAAJwCAYAAAA+1wRiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABok0lEQVR4nOzdebhVdaE//vfhAEcCHEi7N+chyemiAmklUvbN9HZzTJmUJpwFc0YNQSxFU9CryFVvVooJYmZ2tfSXXhVJQuOG3nDKIcUxFUtA4ABn//6wc66EMpyEtVi+Xs/DI6y93Od9Pp+91157v/daq65Wq9UCAAAAAAAAFdWm6AAAAAAAAACwOinEAAAAAAAAqDSFGAAAAAAAAJWmEAMAAAAAAKDSFGIAAAAAAABUmkIMAAAAAACASlOILcfMmTOLjvC+ZGsd2VqnrNnKmiuRrbVkax3ZWke21pGtdWRrHdlWXVlzJbK1lmytI1vryNY6srWObK1T1mxlzZXI1lqytY5srbOmsinElmPBggVFR3hfsrWObK1T1mxlzZXI1lqytY5srSNb68jWOrK1jmyrrqy5EtlaS7bWka11ZGsd2VpHttYpa7ay5kpkay3ZWke21llT2RRiAAAAAAAAVJpCDAAAAAAAgEpTiAEAAAAAAFBpCjEAAAAAAAAqTSEGAAAAAABApSnEAAAAAAAAqDSFGAAAAAAAAJWmEAMAAAAAAKDSFGIAAAAAAABUmkIMAAAAAACASlOIAQAAAAAAUGkKMQAAAAAAACpNIQYAAAAAAEClKcQAAAAAAACoNIUYAAAAAAAAlaYQAwAAAAAAoNIUYgAAAAAAAFSaQgwAAAAAAIBKU4gBAAAAAABQaQoxAAAAAAAAKk0hBgAAAAAAQKUpxAAAAAAAAKg0hRgAAAAAAACVphBbjoaGhqIjAAAAAAAA8A9qW3SAInztmmmZ9eb8lVv5jnuXe/NmG3TIdYN2/8dDAQAAAAAAsFp8KAuxWW/Oz7Ovzys6BgAAAAAAAGuAUyYCAAAAAABQaQoxAAAAAAAAKk0hBgAAAAAAQKUpxAAAAAAAAKg0hRgAAAAAAACVphADAAAAAACg0hRiAAAAAAAAVJpCDAAAAAAAgEpTiAEAAAAAAFBpCjEAAAAAAAAqTSEGAAAAAABApSnEAAAAAAAAqDSFGAAAAAAAAJWmEAMAAAAAAKDSFGIAAAAAAABUmkIMAAAAAACASlOIAQAAAAAAUGkKMQAAAAAAACpNIQYAAAAAAECltV3RCj/72c9yyy23JEkWLlyYxx57LDfccEPOP//81NXVZdttt82IESPSpk2bTJo0KRMnTkzbtm1z7LHHZq+99sqCBQty2mmn5Y033kjHjh1z4YUXpkuXLpkxY0bOO++81NfXp1evXhk8eHCSZOzYsbn33nvTtm3bnHXWWenWrdvqHQEAAAAAAAAqbYVHiB188MEZP358xo8fnx133DHDhg3LFVdckRNPPDE33HBDarVa7r777rz22msZP358Jk6cmGuuuSZjxoxJY2NjJkyYkK5du+aGG27IgQcemHHjxiVJRowYkdGjR2fChAl5+OGHM3PmzMycOTMPPvhgbrrppowZMyYjR45c7QMAAAAAAABAta30KRP/93//N0899VT69u2bmTNnZrfddkuS9O7dOw888EAeeeSR7Lrrrmnfvn06d+6czTffPI8//nimT5+ePffcs2XdqVOnZu7cuWlsbMzmm2+eurq69OrVK1OnTs306dPTq1ev1NXVZeONN86SJUsye/bs1fObAwAAAAAA8KGw0oXYVVddleOPPz5JUqvVUldXlyTp2LFj5syZk7lz56Zz584t63fs2DFz585davm71+3UqdNS6y5vOQAAAAAAALRWXa1Wq61opbfeeiv9+vXLL3/5yyTvHOk1efLkJMldd92VBx54IHvssUfuv//+nHPOOUmS448/Psccc0yuuuqqHHXUUenWrVvmzJmT/v37Z+LEienTp0/L/V177bVZvHhx2rVrl4ULF+bII49Mkhx44IH54Q9/mC5duqzULzNz5swsWLBgues0NDRkyB2v59nX563Ufa7IVht2zOX7bpiFCxd+IPcHAAAAAADAquvRo8f73tZ2Ze7goYceymc/+9mWf++www6ZNm1adt9990yePDmf/vSn061bt1x66aVZuHBhGhsb8/TTT6dr167p3r177rvvvnTr1i2TJ09Ojx490qlTp7Rr1y7PP/98Nttss0yZMiWDBw9OfX19LrroogwaNCivvPJKmpqaVroMS5Idd9xx5Va8496Vvs+VsdNOO32g97cypk+fvtyJLZJsrSPbqitrrkS21pKtdWRrHdlaR7bWka11ZFt1Zc2VyNZasrWObK0jW+vI1jqytU5Zs5U1VyJba8nWOrK1zprKtlKF2LPPPptNN9205d9Dhw7N2WefnTFjxmTrrbfOPvvsk/r6+gwcODADBgxIrVbLSSedlIaGhvTv3z9Dhw5N//79065du4wePTpJMnLkyJx66qlZsmRJevXqlZ133jlJ0rNnz/Tt2zdNTU0ZPnz4aviVAQAAAAAA+DBZqULsiCOOWOrfW221Va6//vpl1uvTp0/69Omz1LIOHTrksssuW2bdXXbZJZMmTVpm+ZAhQzJkyJCViQUAAAAAAAAr1KboAAAAAAAAALA6KcQAAAAAAACoNIUYAAAAAAAAlaYQAwAAAAAAoNIUYgAAAAAAAFSaQgwAAAAAAIBKU4gBAAAAAABQaQoxAAAAAAAAKk0hBgAAAAAAQKUpxAAAAAAAAKg0hRgAAAAAAACVphADAAAAAACg0hRiAAAAAAAAVJpCDAAAAAAAgEpTiAEAAAAAAFBpCjEAAAAAAAAqTSEGAAAAAABApSnEAAAAAAAAqDSFGAAAAAAAAJWmEAMAAAAAAKDSFGIAAAAAAABUmkIMAAAAAACASlOIAQAAAAAAUGkKMQAAAAAAACpNIQYAAAAAAEClKcQAAAAAAACoNIUYAAAAAAAAlaYQAwAAAAAAoNIUYgAAAAAAAFSaQgwAAAAAAIBKU4gBAAAAAABQaQoxAAAAAAAAKk0hBgAAAAAAQKUpxAAAAAAAAKg0hRgAAAAAAACVphADAAAAAACg0hRiAAAAAAAAVJpCDAAAAAAAgEpTiAEAAAAAAFBpCjEAAAAAAAAqTSEGAAAAAABApSnEAAAAAAAAqDSFGAAAAAAAAJWmEAMAAAAAAKDSFGIAAAAAAABUmkIMAAAAAACASlOIAQAAAAAAUGkKMQAAAAAAACpNIQYAAAAAAEClKcQAAAAAAACoNIUYAAAAAAAAlaYQAwAAAAAAoNIUYgAAAAAAAFSaQgwAAAAAAIBKU4gBAAAAAABQaQoxAAAAAAAAKk0hBgAAAAAAQKUpxAAAAAAAAKg0hRgAAAAAAACVphADAAAAAACg0hRiAAAAAAAAVJpCDAAAAAAAgEpTiAEAAAAAAFBpbVdmpauuuir//d//nUWLFqV///7ZbbfdcsYZZ6Suri7bbrttRowYkTZt2mTSpEmZOHFi2rZtm2OPPTZ77bVXFixYkNNOOy1vvPFGOnbsmAsvvDBdunTJjBkzct5556W+vj69evXK4MGDkyRjx47Nvffem7Zt2+ass85Kt27dVusAAAAAAAAAUG0rPEJs2rRp+f3vf58JEyZk/PjxeeWVVzJq1KiceOKJueGGG1Kr1XL33Xfntddey/jx4zNx4sRcc801GTNmTBobGzNhwoR07do1N9xwQw488MCMGzcuSTJixIiMHj06EyZMyMMPP5yZM2dm5syZefDBB3PTTTdlzJgxGTly5GofAAAAAAAAAKpthYXYlClT0rVr1xx//PE55phj8vnPfz4zZ87MbrvtliTp3bt3HnjggTzyyCPZdddd0759+3Tu3Dmbb755Hn/88UyfPj177rlny7pTp07N3Llz09jYmM033zx1dXXp1atXpk6dmunTp6dXr16pq6vLxhtvnCVLlmT27NmrdwQAAAAAAACotLparVZb3grDhg3LSy+9lCuvvDIvvPBCjj322MybNy9TpkxJkkydOjU333xz9txzzzz55JM57bTTkiSnn356DjzwwFx99dU5++yzs80226SpqSmf//znM2nSpAwZMiQ33XRTkuSnP/1pZs2alYaGhqy//voZMGBAkuSwww7L+eefny222GKlfpmZM2dmwYIFy12noaEhQ+54Pc++Pm+l7nNFttqwYy7fd8MsXLjwA7k/AAAAAAAAVl2PHj3e97YVXkNs/fXXz9Zbb5327dtn6623TkNDQ1555ZWW2+fNm5d11103nTp1yrx585Za3rlz56WWL2/dddddN+3atXvP+1hZO+6448qteMe9K32fK2OnnXb6QO9vZUyfPn25E1sk2VpHtlVX1lyJbK0lW+vI1jqytY5srSNb68i26sqaK5GttWRrHdlaR7bWka11ZGudsmYra65EttaSrXVka501lW2Fp0zs0aNH7r///tRqtbz66quZP39+PvOZz2TatGlJksmTJ6dnz57p1q1bpk+fnoULF2bOnDl5+umn07Vr13Tv3j333Xdfy7o9evRIp06d0q5duzz//POp1WqZMmVKevbsme7du2fKlClpamrKSy+9lKampnTp0mX1jgAAAAAAAACVtsIjxPbaa6889NBDOeSQQ1Kr1TJ8+PBsuummOfvsszNmzJhsvfXW2WeffVJfX5+BAwdmwIABqdVqOemkk9LQ0JD+/ftn6NCh6d+/f9q1a5fRo0cnSUaOHJlTTz01S5YsSa9evbLzzjsnSXr27Jm+ffumqakpw4cPX72/PQAAAAAAAJW3wkIseed6YH/v+uuvX2ZZnz590qdPn6WWdejQIZdddtky6+6yyy6ZNGnSMsuHDBmSIUOGrEwsAAAAAAAAWKEVnjIRAAAAAAAA1mYKMQAAAAAAACpNIQYAAAAAAEClKcQAAAAAAACoNIUYAAAAAAAAlaYQAwAAAAAAoNIUYgAAAAAAAFSaQgwAAAAAAIBKU4gBAAAAAABQaQoxAAAAAAAAKk0hBgAAAAAAQKUpxAAAAAAAAKg0hRgAAAAAAACVphADAAAAAACg0hRiAAAAAAAAVJpCDAAAAAAAgEpTiAEAAAAAAFBpCjEAAAAAAAAqTSEGAAAAAABApSnEAAAAAAAAqDSFGAAAAAAAAJWmEAMAAAAAAKDSFGIAAAAAAABUmkIMAAAAAACASlOIAQAAAAAAUGkKMQAAAAAAACpNIQYAAAAAAEClKcQAAAAAAACoNIUYAAAAAAAAlaYQAwAAAAAAoNIUYgAAAAAAAFSaQgwAAAAAAIBKU4gBAAAAAABQaQoxAAAAAAAAKk0hBgAAAAAAQKUpxAAAAAAAAKg0hRgAAAAAAACVphADAAAAAACg0hRiAAAAAAAAVJpCDAAAAAAAgEpTiAEAAAAAAFBpCjEAAAAAAAAqTSEGAAAAAABApSnEAAAAAAAAqDSFGAAAAAAAAJWmEAMAAAAAAKDSFGIAAAAAAABUmkIMAAAAAACASlOIAQAAAAAAUGkKMQAAAAAAACpNIQYAAAAAAEClKcQAAAAAAACoNIUYAAAAAAAAlaYQAwAAAAAAoNIUYgAAAAAAAFSaQgwAAAAAAIBKU4gBAAAAAABQaQoxAAAAAAAAKk0hBgAAAAAAQKUpxAAAAAAAAKg0hRgAAAAAAACVphADAAAAAACg0tquzEoHHnhgOnfunCTZdNNNc8wxx+SMM85IXV1dtt1224wYMSJt2rTJpEmTMnHixLRt2zbHHnts9tprryxYsCCnnXZa3njjjXTs2DEXXnhhunTpkhkzZuS8885LfX19evXqlcGDBydJxo4dm3vvvTdt27bNWWedlW7duq2+3x4AAAAAAIDKW2EhtnDhwiTJ+PHjW5Ydc8wxOfHEE7P77rtn+PDhufvuu7PLLrtk/Pjxufnmm7Nw4cIMGDAge+yxRyZMmJCuXbtmyJAhuf322zNu3LgMGzYsI0aMyOWXX57NNtssRx11VGbOnJkkefDBB3PTTTfl5ZdfzpAhQ3LzzTevpl8dAAAAAACAD4MVFmKPP/545s+fn29961tZvHhxTj755MycOTO77bZbkqR37975zW9+kzZt2mTXXXdN+/bt0759+2y++eZ5/PHHM3369BxxxBEt644bNy5z585NY2NjNt988yRJr169MnXq1LRv3z69evVKXV1dNt544yxZsiSzZ89Oly5dVuMQAAAAAAAAUGUrLMTWWWedDBo0KIceemj+9Kc/5cgjj0ytVktdXV2SpGPHjpkzZ07mzp3bclrF5uVz585davm71+3UqdNS686aNSsNDQ1Zf/31l1o+Z84chRgAAAAAAACtVler1WrLW6GxsTFNTU1ZZ511kiSHHHJIZs6cmcceeyxJctddd+WBBx7IHnvskfvvvz/nnHNOkuT444/PMccck6uuuipHHXVUunXrljlz5qR///6ZOHFi+vTpk1/+8pdJkmuvvTaLFy9Ou3btsnDhwhx55JFJ3rl22Q9/+MOVLsRmzpyZBQsWLHedhoaGDLnj9Tz7+ryVus8V2WrDjrl83w1bTi0JAAAAAADAmtejR4/3vW2FR4j99Kc/zZNPPplzzjknr776aubOnZs99tgj06ZNy+67757Jkyfn05/+dLp165ZLL700CxcuTGNjY55++ul07do13bt3z3333Zdu3bpl8uTJ6dGjRzp16pR27drl+eefz2abbZYpU6Zk8ODBqa+vz0UXXZRBgwbllVdeSVNT0yodHbbjjjuu3Ip33LvS97kydtpppw/0/lbG9OnTlzuxRZKtdWRbdWXNlcjWWrK1jmytI1vryNY6srWObKuurLkS2VpLttaRrXVkax3ZWke21ilrtrLmSmRrLdlaR7bWWVPZVliIHXLIITnzzDPTv3//1NXV5fzzz88GG2yQs88+O2PGjMnWW2+dffbZJ/X19Rk4cGAGDBiQWq2Wk046KQ0NDenfv3+GDh2a/v37p127dhk9enSSZOTIkTn11FOzZMmS9OrVKzvvvHOSpGfPnunbt2+ampoyfPjw1fvbAwAAAAAAUHkrLMTat2/fUmK92/XXX7/Msj59+qRPnz5LLevQoUMuu+yyZdbdZZddMmnSpGWWDxkyJEOGDFlRLAAAAAAAAFgpbYoOAAAAAAAAAKuTQgwAAAAAAIBKU4gBAAAAAABQaQoxAAAAAAAAKk0hBgAAAAAAQKUpxAAAAAAAAKg0hRgAAAAAAACVphADAAAAAACg0hRiAAAAAAAAVJpCDAAAAAAAgEpTiAEAAAAAAFBpCjEAAAAAAAAqTSEGAAAAAABApSnEAAAAAAAAqDSFGAAAAAAAAJWmEAMAAAAAAKDSFGIAAAAAAABUmkIMAAAAAACASlOIAQAAAAAAUGkKMQAAAAAAACpNIQYAAAAAAEClKcQAAAAAAACoNIUYAAAAAAAAlaYQAwAAAAAAoNIUYgAAAAAAAFSaQgwAAAAAAIBKU4gBAAAAAABQaQoxAAAAAAAAKk0hBgAAAAAAQKUpxAAAAAAAAKg0hRgAAAAAAACVphADAAAAAACg0hRiAAAAAAAAVJpCDAAAAAAAgEpTiAEAAAAAAFBpCjEAAAAAAAAqTSEGAAAAAABApSnEAAAAAAAAqDSFGAAAAAAAAJWmEAMAAAAAAKDSFGIAAAAAAABUmkIMAAAAAACASlOIAQAAAAAAUGkKMQAAAAAAACpNIQYAAAAAAEClKcQAAAAAAACoNIUYAAAAAAAAlaYQAwAAAAAAoNIUYgAAAAAAAFSaQgwAAAAAAIBKU4gBAAAAAABQaQoxAAAAAAAAKk0hBgAAAAAAQKUpxAAAAAAAAKg0hRgAAAAAAACVphADAAAAAACg0hRiAAAAAAAAVJpCDAAAAAAAgEpTiAEAAAAAAFBpCjEAAAAAAAAqTSEGAAAAAABApSnEAAAAAAAAqLSVKsTeeOONfO5zn8vTTz+d5557Lv3798+AAQMyYsSINDU1JUkmTZqUgw8+OH369Mk999yTJFmwYEGGDBmSAQMG5Mgjj8zs2bOTJDNmzMihhx6afv36ZezYsS0/Z+zYsTnkkEPSr1+/PPLIIx/07woAAAAAAMCH0AoLsUWLFmX48OFZZ511kiSjRo3KiSeemBtuuCG1Wi133313XnvttYwfPz4TJ07MNddckzFjxqSxsTETJkxI165dc8MNN+TAAw/MuHHjkiQjRozI6NGjM2HChDz88MOZOXNmZs6cmQcffDA33XRTxowZk5EjR67e3xwAAAAAAIAPhRUWYhdeeGH69euXj33sY0mSmTNnZrfddkuS9O7dOw888EAeeeSR7Lrrrmnfvn06d+6czTffPI8//nimT5+ePffcs2XdqVOnZu7cuWlsbMzmm2+eurq69OrVK1OnTs306dPTq1ev1NXVZeONN86SJUtajigDAAAAAACA1lpuIfazn/0sXbp0aSm1kqRWq6Wuri5J0rFjx8yZMydz585N586dW9bp2LFj5s6du9Tyd6/bqVOnpdZd3nIAAAAAAAD4R9TVarXa+9142GGHpa6uLnV1dXnsscey5ZZb5tFHH82jjz6aJLnrrrvywAMPZI899sj999+fc845J0ly/PHH55hjjslVV12Vo446Kt26dcucOXPSv3//TJw4MX369Mkvf/nLJMm1116bxYsXp127dlm4cGGOPPLIJMmBBx6YH/7wh+nSpctK/zIzZ87MggULlrtOQ0NDhtzxep59fd5K3+/ybLVhx1y+74ZZuHDhB3J/AAAAAAAArLoePXq8721tl/c//uQnP2n5+8CBA3POOefkoosuyrRp07L77rtn8uTJ+fSnP51u3brl0ksvzcKFC9PY2Jinn346Xbt2Tffu3XPfffelW7dumTx5cnr06JFOnTqlXbt2ef7557PZZptlypQpGTx4cOrr63PRRRdl0KBBeeWVV9LU1LRKZViS7Ljjjiu34h33rtL9rshOO+30gd7fypg+ffpyJ7ZIsrWObKuurLkS2VpLttaRrXVkax3ZWke21pFt1ZU1VyJba8nWOrK1jmytI1vryNY6Zc1W1lyJbK0lW+vI1jprKttyC7H3MnTo0Jx99tkZM2ZMtt566+yzzz6pr6/PwIEDM2DAgNRqtZx00klpaGhI//79M3To0PTv3z/t2rXL6NGjkyQjR47MqaeemiVLlqRXr17ZeeedkyQ9e/ZM375909TUlOHDh3+wvykAAAAAAAAfSitdiI0fP77l79dff/0yt/fp0yd9+vRZalmHDh1y2WWXLbPuLrvskkmTJi2zfMiQIRkyZMjKRgIAAAAAAIAValN0AAAAAAAAAFidFGIAAAAAAABUmkIMAAAAAACASlOIAQAAAAAAUGkKMQAAAAAAACpNIQYAAAAAAEClKcQAAAAAAACoNIUYAAAAAAAAlaYQAwAAAAAAoNIUYgAAAAAAAFSaQgwAAAAAAIBKU4gBAAAAAABQaQoxAAAAAAAAKk0hBgAAAAAAQKUpxAAAAAAAAKg0hRgAAAAAAACVphADAAAAAACg0hRiAAAAAAAAVJpCDAAAAAAAgEpTiAEAAAAAAFBpCjEAAAAAAAAqTSEGAAAAAABApSnEAAAAAAAAqDSFGAAAAAAAAJWmEAMAAAAAAKDSFGIAAAAAAABUmkIMAAAAAACASlOIAQAAAAAAUGkKMQAAAAAAACpNIQYAAAAAAEClKcQAAAAAAACoNIUYAAAAAAAAlaYQAwAAAAAAoNIUYgAAAAAAAFSaQgwAAAAAAIBKU4gBAAAAAABQaQoxAAAAAAAAKk0hBgAAAAAAQKUpxAAAAAAAAKg0hRgAAAAAAACVphADAAAAAACg0hRiAAAAAAAAVJpCDAAAAAAAgEpTiAEAAAAAAFBpCjEAAAAAAAAqTSEGAAAAAABApSnEAAAAAAAAqDSFGAAAAAAAAJWmEAMAAAAAAKDSFGIAAAAAAABUmkIMAAAAAACASlOIAQAAAAAAUGkKMQAAAAAAACpNIQYAAAAAAEClKcQAAAAAAACoNIUYAAAAAAAAlaYQAwAAAAAAoNIUYgAAAAAAAFSaQgwAAAAAAIBKU4gBAAAAAABQaQoxAAAAAAAAKk0hBgAAAAAAQKUpxAAAAAAAAKi0titaYcmSJRk2bFieffbZ1NfXZ9SoUanVajnjjDNSV1eXbbfdNiNGjEibNm0yadKkTJw4MW3bts2xxx6bvfbaKwsWLMhpp52WN954Ix07dsyFF16YLl26ZMaMGTnvvPNSX1+fXr16ZfDgwUmSsWPH5t57703btm1z1llnpVu3bqt9EAAAAAAAAKiuFRZi99xzT5Jk4sSJmTZtWkshduKJJ2b33XfP8OHDc/fdd2eXXXbJ+PHjc/PNN2fhwoUZMGBA9thjj0yYMCFdu3bNkCFDcvvtt2fcuHEZNmxYRowYkcsvvzybbbZZjjrqqMycOTNJ8uCDD+amm27Kyy+/nCFDhuTmm29evSMAAAAAAABApa2wEPviF7+Yz3/+80mSl156KRtuuGHuvffe7LbbbkmS3r175ze/+U3atGmTXXfdNe3bt0/79u2z+eab5/HHH8/06dNzxBFHtKw7bty4zJ07N42Njdl8882TJL169crUqVPTvn379OrVK3V1ddl4442zZMmSzJ49O126dFlNvz4AAAAAAABVV1er1Wors+LQoUPz61//OpdddlnOOOOMTJkyJUkyderU3Hzzzdlzzz3z5JNP5rTTTkuSnH766TnwwANz9dVX5+yzz84222yTpqamfP7zn8+kSZMyZMiQ3HTTTUmSn/70p5k1a1YaGhqy/vrrZ8CAAUmSww47LOeff3622GKLlfplZs6cmQULFix3nYaGhgy54/U8+/q8lbrPFdlqw465fN8Ns3Dhwg/k/gAAAAAAAFh1PXr0eN/bVniEWLMLL7wwp556avr06bNU+TNv3rysu+666dSpU+bNm7fU8s6dOy+1fHnrrrvuumnXrt173sfK2nHHHVduxTvuXen7XBk77bTTB3p/K2P69OnLndgiydY6sq26suZKZGst2VpHttaRrXVkax3ZWke2VVfWXIlsrSVb68jWOrK1jmytI1vrlDVbWXMlsrWWbK0jW+usqWxtVrTCz3/+81x11VVJkg4dOqSuri477bRTpk2bliSZPHlyevbsmW7dumX69OlZuHBh5syZk6effjpdu3ZN9+7dc99997Ws26NHj3Tq1Cnt2rXL888/n1qtlilTpqRnz57p3r17pkyZkqamprz00ktpampyukQAAAAAAAD+ISs8QuxLX/pSzjzzzBx22GFZvHhxzjrrrGyzzTY5++yzM2bMmGy99dbZZ599Ul9fn4EDB2bAgAGp1Wo56aST0tDQkP79+2fo0KHp379/2rVrl9GjRydJRo4cmVNPPTVLlixJr169svPOOydJevbsmb59+6apqSnDhw9fvb89AAAAAAAAlbfCQuwjH/lI/v3f/32Z5ddff/0yy/r06ZM+ffostaxDhw657LLLlll3l112yaRJk5ZZPmTIkAwZMmRFsQAAAAAAAGClrPCUiQAAAAAAALA2U4gBAAAAAABQaQoxAAAAAAAAKk0hBgAAAAAAQKUpxAAAAAAAAKg0hRgAAAAAAACVphADAAAAAACg0hRiAAAAAAAAVJpCDAAAAAAAgEpTiAEAAAAAAFBpCjEAAAAAAAAqTSEGAAAAAABApSnEAAAAAAAAqDSFGAAAAAAAAJWmEAMAAAAAAKDSFGIAAAAAAABUmkIMAAAAAACASlOIAQAAAAAAUGkKMQAAAAAAACpNIQYAAAAAAEClKcQAAAAAAACoNIUYAAAAAAAAlaYQAwAAAAAAoNIUYgAAAAAAAFSaQgwAAAAAAIBKU4gBAAAAAABQaQoxAAAAAAAAKk0hBgAAAAAAQKUpxAAAAAAAAKg0hRgAAAAAAACVphADAAAAAACg0hRiAAAAAAAAVJpCDAAAAAAAgEpTiAEAAAAAAFBpCjEAAAAAAAAqTSEGAAAAAABApSnEAAAAAAAAqDSFGAAAAAAAAJWmEAMAAAAAAKDSFGIAAAAAAABUmkIMAAAAAACASlOIAQAAAAAAUGkKMQAAAAAAACpNIQYAAAAAAEClKcQAAAAAAACoNIUYAAAAAAAAlaYQAwAAAAAAoNIUYgAAAAAAAFSaQgwAAAAAAIBKU4gBAAAAAABQaQoxAAAAAAAAKk0hBgAAAAAAQKUpxAAAAAAAAKg0hRgAAAAAAACVphADAAAAAACg0hRiAAAAAAAAVJpCDAAAAAAAgEpTiAEAAAAAAFBpCjEAAAAAAAAqTSEGAAAAAABApSnEAAAAAAAAqDSFGAAAAAAAAJXWdnk3Llq0KGeddVZefPHFNDY25thjj80nPvGJnHHGGamrq8u2226bESNGpE2bNpk0aVImTpyYtm3b5thjj81ee+2VBQsW5LTTTssbb7yRjh075sILL0yXLl0yY8aMnHfeeamvr0+vXr0yePDgJMnYsWNz7733pm3btjnrrLPSrVu3NTIIAAAAAAAAVNdyC7Ff/OIXWX/99XPRRRflzTffzEEHHZTtttsuJ554YnbfffcMHz48d999d3bZZZeMHz8+N998cxYuXJgBAwZkjz32yIQJE9K1a9cMGTIkt99+e8aNG5dhw4ZlxIgRufzyy7PZZpvlqKOOysyZM5MkDz74YG666aa8/PLLGTJkSG6++eY1MggAAAAAAABU13ILsX333Tf77LNPy7/r6+szc+bM7LbbbkmS3r175ze/+U3atGmTXXfdNe3bt0/79u2z+eab5/HHH8/06dNzxBFHtKw7bty4zJ07N42Njdl8882TJL169crUqVPTvn379OrVK3V1ddl4442zZMmSzJ49O126dFldvzsAAAAAAAAfAsu9hljHjh3TqVOnzJ07NyeccEJOPPHE1Gq11NXVtdw+Z86czJ07N507d17q/5s7d+5Sy9+9bqdOnZZad3nLAQAAAAAA4B9RV6vVastb4eWXX87xxx+fAQMG5JBDDknv3r0zefLkJMldd92VBx54IHvssUfuv//+nHPOOUmS448/Psccc0yuuuqqHHXUUenWrVvmzJmT/v37Z+LEienTp09++ctfJkmuvfbaLF68OO3atcvChQtz5JFHJkkOPPDA/PCHP1ylI8RmzpyZBQsWLHedhoaGDLnj9Tz7+ryVvt/l2WrDjrl83w2zcOHCD+T+AAAAAAAAWHU9evR439uWe8rE119/Pd/61rcyfPjwfOYzn0mS7LDDDpk2bVp23333TJ48OZ/+9KfTrVu3XHrppVm4cGEaGxvz9NNPp2vXrunevXvuu+++dOvWLZMnT06PHj3SqVOntGvXLs8//3w222yzTJkyJYMHD059fX0uuuiiDBo0KK+88kqamppW+XSJO+6448qteMe9q3S/K7LTTjt9oPe3MqZPn77ciS2SbK0j26ora65EttaSrXVkax3ZWke21pGtdWRbdWXNlcjWWrK1jmytI1vryNY6srVOWbOVNVciW2vJ1jqytc6ayrbcQuzKK6/MW2+9lXHjxmXcuHFJku985zv53ve+lzFjxmTrrbfOPvvsk/r6+gwcODADBgxIrVbLSSedlIaGhvTv3z9Dhw5N//79065du4wePTpJMnLkyJx66qlZsmRJevXqlZ133jlJ0rNnz/Tt2zdNTU0ZPnz4av7VAQAAAAAA+DBYbiE2bNiwDBs2bJnl119//TLL+vTpkz59+iy1rEOHDrnsssuWWXeXXXbJpEmTllk+ZMiQDBkyZIWhAQAAAAAAYGW1KToAAAAAAAAArE4KMQAAAAAAACpNIQYAAAAAAEClKcQAAAAAAACoNIUYAAAAAAAAlaYQAwAAAAAAoNIUYgAAAAAAAFSaQgwAAAAAAIBKU4gBAAAAAABQaQoxAAAAAAAAKk0hBgAAAAAAQKUpxAAAAAAAAKg0hRgAAAAAAACVphADAAAAAACg0hRiAAAAAAAAVJpCDAAAAAAAgEpTiAEAAAAAAFBpCjEAAAAAAAAqTSEGAAAAAABApSnEAAAAAAAAqDSFGAAAAAAAAJWmEAMAAAAAAKDSFGIAAAAAAABUmkIMAAAAAACASlOIAQAAAAAAUGkKMQAAAAAAACpNIQYAAAAAAEClKcQAAAAAAACoNIUYAAAAAAAAlaYQAwAAAAAAoNIUYgAAAAAAAFSaQgwAAAAAAIBKU4gBAAAAAABQaQoxAAAAAAAAKk0hBgAAAAAAQKUpxAAAAAAAAKg0hRgAAAAAAACVphADAAAAAACg0hRiAAAAAAAAVJpCDAAAAAAAgEpTiAEAAAAAAFBpCjEAAAAAAAAqTSEGAAAAAABApSnEAAAAAAAAqDSFGAAAAAAAAJWmEAMAAAAAAKDSFGIAAAAAAABUmkIMAAAAAACASlOIAQAAAAAAUGkKMQAAAAAAACpNIQYAAAAAAEClKcQAAAAAAACoNIUYAAAAAAAAlaYQAwAAAAAAoNIUYgAAAAAAAFSaQgwAAAAAAIBKU4gBAAAAAABQaQoxAAAAAAAAKk0hBgAAAAAAQKUpxAAAAAAAAKg0hRgAAAAAAACVphADAAAAAACg0hRiAAAAAAAAVNpKFWIPP/xwBg4cmCR57rnn0r9//wwYMCAjRoxIU1NTkmTSpEk5+OCD06dPn9xzzz1JkgULFmTIkCEZMGBAjjzyyMyePTtJMmPGjBx66KHp169fxo4d2/Jzxo4dm0MOOST9+vXLI4888oH+ogAAAAAAAHw4rbAQ+8///M8MGzYsCxcuTJKMGjUqJ554Ym644YbUarXcfffdee211zJ+/PhMnDgx11xzTcaMGZPGxsZMmDAhXbt2zQ033JADDzww48aNS5KMGDEio0ePzoQJE/Lwww9n5syZmTlzZh588MHcdNNNGTNmTEaOHLl6f3MAAAAAAAA+FFZYiG2++ea5/PLLW/49c+bM7LbbbkmS3r1754EHHsgjjzySXXfdNe3bt0/nzp2z+eab5/HHH8/06dOz5557tqw7derUzJ07N42Njdl8881TV1eXXr16ZerUqZk+fXp69eqVurq6bLzxxlmyZEnLEWUAAAAAAADQWnW1Wq22opVeeOGFnHzyyZk0aVJ69eqVKVOmJEmmTp2am2++OXvuuWeefPLJnHbaaUmS008/PQceeGCuvvrqnH322dlmm23S1NSUz3/+85k0aVKGDBmSm266KUny05/+NLNmzUpDQ0PWX3/9DBgwIEly2GGH5fzzz88WW2yx0r/MzJkzs2DBguWu09DQkCF3vJ5nX5+30ve7PFtt2DGX77thyxF0AAAAAAAArHk9evR439varuqdtWnzfweVzZs3L+uuu246deqUefPmLbW8c+fOSy1f3rrrrrtu2rVr9573sSp23HHHlVvxjntX6X5XZKeddvpA729l/OEPfyjk566M6dOnL/dBVyTZWqes2cqaK5GttWRrHdlaR7bWka11ZGsd2VZdWXMlsrWWbK0jW+vI1jqytY5srVPWbGXNlcjWWrK1jmyts6ayrXIhtsMOO2TatGnZfffdM3ny5Hz6059Ot27dcumll2bhwoVpbGzM008/na5du6Z79+6577770q1bt0yePDk9evRIp06d0q5duzz//PPZbLPNMmXKlAwePDj19fW56KKLMmjQoLzyyitpampKly5dVsfvXGpfu2ZaZr05f+VWXkGxt9kGHXLdoN3/8VAAAAAAAABrsVUuxIYOHZqzzz47Y8aMydZbb5199tkn9fX1GThwYAYMGJBarZaTTjopDQ0N6d+/f4YOHZr+/funXbt2GT16dJJk5MiROfXUU7NkyZL06tUrO++8c5KkZ8+e6du3b5qamjJ8+PAP9jddS8x6c/4HdjpHAAAAAAAAVrIQ23TTTTNp0qQkyVZbbZXrr79+mXX69OmTPn36LLWsQ4cOueyyy5ZZd5dddmm5v3cbMmRIhgwZslLBAQAAAAAAYGW0WfEqAAAAAAAAsPZSiAEAAAAAAFBpCjEAAAAAAAAqTSEGAAAAAABApSnEAAAAAAAAqDSFGAAAAAAAAJWmEAMAAAAAAKDSFGIAAAAAAABUmkIMAAAAAACASlOIAQAAAAAAUGkKMQAAAAAAACpNIQYAAAAAAEClKcQAAAAAAACoNIUYAAAAAAAAlaYQAwAAAAAAoNIUYgAAAAAAAFSaQgwAAAAAAIBKU4jxgWtoaCg6AgAAAAAAQIu2RQdg7fG1a6Zl1pvzV27lO+5d7s2bbdAh1w3a/R8PBQAAAAAAsAIKMVbarDfn59nX5xUdAwAAAAAAYJU4ZSIAAAAAAACVphADAAAAAACg0hRiAAAAAAAAVJpCjA+VhoaGoiMAAAAAAABrWNuiA8AH4WvXTMusN+ev3Mp33Pu+N222QYdcN2j3DyYUAAAAAABQCgoxKmHWm/Pz7Ovzio4BAAAAAACUkFMmAgAAAAAAUGkKMQAAAAAAACpNIQYAAAAAAEClKcQAAAAAAACoNIUYAAAAAAAAlaYQg5JoaGgoOgIAAAAAAFRS26IDQNV97ZppmfXm/JVb+Y573/emzTbokOsG7f7BhAIAAAAAgA8RhRisZrPenJ9nX59XdAwAAAAAAPjQcspEAAAAAAAAKk0hBqyQ65sBAAAAALA2c8pE+BBzfTMAAAAAAD4MFGLwIba2X9/MkWsAAAAAAKwMhRhQSit99NpyjlxLHL0GAAAAAIBCDCgpR68BAAAAAPBBUYgBrKK1/eg1ZR0AAAAA8GGjEANYRWU+em1tL+sAAAAAAFYHhRhAhZS5rFsZjl4DAAAAAFYHhRgAa4Sj1wAAAACAoijEAFgj1vaj1wAAAACAtVebogMAAAAAAADA6qQQAwAAAAAAoNIUYgAAAAAAAFSaQgwAVkJDQ0PREQAAAACAVmpbdAAAKNLXrpmWWW/OX7mV77h3uTdvtkGHXDdo93881CpS1gEAAADA8inEAPhQm/Xm/Dz7+ryiY7wnZd3qVeZsAAAAAHywFGIAUFLKutYpc7aVpawDAAAA+GApxACAVVbmsq7M2apQ1gEAAACsjRRiAABrSJnLupXl6DUAAABgbaQQAwDA0WsAAABApSnEAABw9NpqVuZsAAAA8GGgEAMAoNTKfPTaB5WtyKPqlHUAAAB8GCjEAAAotTIfvVbmbMo6AAAA+D8KMQAAqCBlHQAAAPwfhRgAALBGlbmsW1llPXqtrLkAAACKphADAAD4mzIfvbbS2dbwtfQAAADWBgoxAACAvynz0WtlzrYyynz0mmwAAFB9pSvEmpqacs455+SJJ55I+/bt873vfS9bbLFF0bEAAAB4H2U+ek221UdZBwDA2qR0hdhdd92VxsbG3HjjjZkxY0YuuOCC/Md//EfRsQAAAHgfZT56TbZV90GdOjRR1r0X2QAAilG6Qmz69OnZc889kyS77LJL/vCHPxScCAAAAD48ylrUJeUu62Rbvcpc1pU5GwDwf0pXiM2dOzedOnVq+Xd9fX0WL16ctm0/uKibbdChlPf1Qd+fbMXdz+q4T9mKvZ/VcZ+yFXs/q+P+ZCv+vj7o+5Ot+Pv6oO+vrNk+TNvdD/I+ZSv2flbHfcpW7P2sjvtbHeNGtZz1s//NK28tWLmVf/fQcm/+53XXyfkH/8sHkOodZc62sspc1snWOmXNVtZciWytJVvryNY6aypbXa1Wq62Rn7SSRo0alZ133jlf/vKXkyS9e/fO5MmTC04FAAAAAADA2qpN0QH+Xvfu3VsKsBkzZqRr164FJwIAAAAAAGBtVrojxJqamnLOOefkySefTK1Wy/nnn59tttmm6FgAAAAAAACspUpXiAEAAAAAAMAHqXSnTAQAAAAAAIAPkkIMAAAAAACASlOIAQAAAAAAUGkKMQAAAAAAACpNIQYAAAAAAEClKcQAAAAAAACoNIUYAAAAAAAAlaYQAwAAAAAAoNIUYgD/oFqtlrvuuiszZszIX//615xxxhk566yz8vrrrxcdba3U1NRUdIS1ak5HjRpVdAQqavbs2bngggtyySWX5M0332xZPnbs2AJTvaPM2d7L448/XnSEJGvfuJXZyy+/XHQEYDlmzZqVF198segYwHJMmTKl6AhLmTNnTubPn7/UsjJuRx588MH87ne/KzoG/6Ann3wyzz333FLLHn744YLS8GHwxhtv5KWXXmr582HWtugArNjydhJ69eq1BpMsa8aMGTn33HPT0NCQU045JT179kySHH/88bniiisKzfZuV155ZX7wgx9knXXWaVlW5M5Xmee0zNmaPfnkkznnnHMyZ86c7Lffftl2222z1157FZbnu9/9bubPn5/XXnstf/nLX9K3b9907Ngxw4YNy5VXXllYrrXJr371qzQ1NaWxsTHf//73c8QRR2TQoEGF5SnznPbr16/l77VaLU8//XTLjvPEiROLipUkufHGG9/3tr59+67BJEsra66yO/3007P33ntn8eLFOfzww3P11Vdnk002yYMPPlh0tFJnS5Z9Lb3oooty2mmnJSn2tbTs41Z21113XdZZZ5289dZb+dnPfpY999wzZ555ZtGxSq2xsfF9b2vfvv0aTLKs2bNn5+qrr05DQ0O+8Y1vZIMNNkjyTkE8ePDgwnLVarXcfffd2XDDDbPVVltl1KhRadOmTU4++eRsuOGGheUqu0ceeSRnn312Ntxww+y33375wQ9+kHbt2mXAgAE59NBDi45XWm+++WbGjRuXjTbaKL17986QIUNSX1+fUaNGZddddy06Hq1Q5u3u3++T/+hHP8o3v/nNJMXvk9900035z//8zzQ1NaVv37458sgjkyRnnnlmrrvuukKz3XvvvTnnnHOy7rrrZp999slDDz2U9u3b58EHH8xxxx1XWK6yv8cq8+eVV1xxRaZMmZLFixdnhx12yDnnnJO6urqMHj268MdbWbchl1xySU466aQ8++yzOe200/LnP/85G2+8cUaNGpWtttqqsFxri3POOSeTJ0/Oxz72sdRqtdTV1RX++VGRz1GF2N/st99+S31T9t2K/tbKpEmT8oc//CG77777MrcVXVBccMEFGT16dBYvXpzTTz89p5xySnr16pW33nqr0Fx/71e/+lXuv//+dOjQoegoSco9p2XO1uy8887LqFGjMmzYsBxyyCE54ogjCi3EHn/88dxwww1pbGzMfvvt1/Kme3k7iGvSmDFj3ve2k08+eQ0meX8//OEPc/XVV+fkk0/Offfdl29961uFFmJlntPDDjssN998c77zne+kQ4cOOeWUUzJ69OiiYyVJnnnmmdxzzz3Zf//9i46ylLLmalbWfZDGxsaWN7Pbb799jjvuuIwfPz61Wq2wTM3KnC1JLr744rRp0yaf/OQnk7zzbbzbb789SbGvpWUft7I+F5rdfvvtGT9+fI444ojcfvvt+frXv150pCTl/kBqv/32yxtvvJH11luv5c1383/vvvvuQrOVtSAu85dykvI+T88///yMGzcuL774Yo499tjcf//9adeuXQYOHFh4IXbKKae8721F78Odfvrp+fKXv5yXXnop3/rWt3L99denQ4cOOe2003L99dcXmq2sj7Wk/NnKut2966678tZbb2XPPfdM8s5+yWuvvVZopmaTJk3KbbfdluSdEuzKK6/MMcccU4p9pHHjxuX222/Pa6+9ln79+mXKlCmpr69P//79Cy3Eyv4eq8yfV06ePDkTJ05MXV1dLrzwwowcOTLnnHNOKR5vZd2G/P73v0/yzryeeeaZ6dGjRx5//PGce+65+dGPflRYrqTcr/PNHnnkkdx1111p06Y8Jwss8jmqEPubsWPH5uSTT85PfvKTpY4iKoNLLrkkAwcOzJFHHpmtt9666DhLadeuXUsTf/XVV+db3/pWNtpoo9TV1RWcbGmbbLJJqea1zHNa5mzvtsUWW6Suri5dunRJx44di46T6dOnp0ePHi0vxM8999xyv1mzJnXp0iUTJkzIscceW4odrPfS0NCQJOnYsWPat2+fefPmFZyovHO633775ROf+ES+//3v58wzz0xDQ0M22WSTomMleefN4zPPPJPevXunW7duRcdpUdZczcq6D7JkyZI88cQT+eQnP5nu3bvn6KOPzrHHHpu333676GilzpYkEyZMyLnnnpvu3bvn0EMPzcCBA0txetOyj1tZnwvN6urq8tprr2XDDTdMXV1d/vrXvxYdKUm5P5CaMGFCBg0alB//+MdZb731io6zlLIWxGX+Uk5S3udpU1NTNtlkk2yyySY5/PDD85GPfCRJSvG+dN99980ll1ySc845p+goy3j77bdz0EEHJXnnNGzN7//KMG5lfawl5c5W5u3u1VdfnUsvvTRLlizJCSeckGnTphV6RO671dfXtxz9cuGFF+aII47IpptuWornQlNTUzp06JAtt9wyQ4YMSdu273yUW/TrVdnfY5X588rmgilJhg4dmlNOOSU/+MEPSpGtzNuQJJk/f3569OiRJNluu+2yePHighOV+3W+2RZbbJGFCxeW5kCRpNjnaHlqwYJtscUW+drXvpZp06YVHWUZ9fX1ufDCC0vxQezf69ixY6677ro0NjZmo402ysUXX5wTTzyxdOdZXrRoUfbbb7+cfPLJOfnkk5fb3q8JZZ7TMmdrtt5662XixImZP39+br/99qy77rqF5jn33HPzwx/+MLVaLRtvvHGSd77pMHTo0EJzNfvGN76Rbt265WMf+1gOOuigpf6UxaabbpqvfvWr+epXv5qxY8cWvkNd9jndfvvt8/3vfz+jR49+32+nFuXCCy9Mly5dio6xjLLmSsq7DzJs2LB873vfa7l23pe//OX06dOnFOcbL3O2JOnQoUNGjRqVOXPmZPjw4VmyZEnRkZKUf9zK+lxotvvuu+fwww/P4YcfnvPPPz9f+tKXio6U5J0PpLbYYov07t07gwcPXupP0bp06ZJTTjkljz76aNFRltFcECdZqiCeO3duwcne+VJO+/btS/elnKS8z9PPfOYz+eY3v5mmpqacdNJJSd7Zn2s+UrdIe++9d/bYY4+88cYb2W233Zb6U7T11lsv48aNS61Wy7XXXpskufXWW1u+rFaksj7WknJnK/N2t66uLieddFK22267nHDCCaXZriXvvA4MGTIkc+bMSdu2bfPv//7v+eEPf1iK68AedNBBOeCAA9LU1JTDDjssSTJkyJD07t274GTlfo9V5s8rv/zlL+eQQw7JX/7ylyTvXBd86tSppbiGWFm3IX/6059a9tPuvPPOLFq0KD/4wQ9avgBTpDK/zjd7+eWXs9dee6Vv377p27fvUpfiKEqRz9G6WtFfKWCtNnfu3JbzPnfq1ClJ8tRTT2XMmDEZN25cwen+z3ud+qRMGyZWzdy5c3PllVfmySefzDbbbJOjjz4666+/ftGxkrzz7a0yHYLcbOHChVm4cGHh5eHyzJs3Lx07dszrr79eqmtklHVOk3e+3f7EE0/kX/7lX4qOsoyyjltZc5Xdu8etbGNY5mxJMnXq1Nx88825+OKLi46ylLKPW1nVarW8+eab6dy5c9q1a1d0nBazZ8/O22+/nU033bToKGuNxx57LOeff34uueSSlv2OW2+9Neeff36hH3I/9dRTueSSSzJ27NiWb8gee+yxOfroo7PLLrsUlmtt8Nhjj2X77bdv+fdvf/vb7LbbbrZvyzF//vxMmjRpqVPAXn311fnqV7+aj370owUmo+r++Mc/5tZbb82pp55adJQW06ZNy6677tpypNjChQszYcKEfOMb3yg2WN653l/ztS6T5Nlnny3VdZPKuC9Z9s8rZ82alY033jj19fUty+6666588YtfLDBVuT3//PP5wx/+kI997GPZaaedMnbs2Bx11FGl/pyrLN6rZCr6TENFPkcVYu/y2GOPZerUqZkzZ07WXXfd9OjRo/CjFJL/u9Dt1KlTM3fu3HTu3Dk9e/bM4MGDS7GTumjRojzxxBMt47btttsWfrHWZvfcc0/22muv9zzFSJHXVCjznJY5W7MlS5bkj3/841LfKCvyuTpr1qyMGjUqf/jDH9K2bds0NTWla9euOfPMM0u1k/rmm2+2zGlZCsRmTzzxRM4666y8+uqr2XDDDXP++ednhx12KCxPmed0bcg2c+bM1NfXlyZbWXO9Wxn3Qd5v3M4666xsueWWsq2AOW2dMo5bs2nTpuWss85Kp06dMmfOnHz3u9/NHnvsUXSspZTxA6m77rprmTndd999S3FaoGZlLYjLlOXdyvo8LWuupNzvmcucrcxzWuZsZd7uljmbOV01a8N7rDJv38o4p2XPVub5LGu2m266KYceemhGjx69zPydfPLJBaX6P0WNm0Lsb8aOHZtHHnkkvXr1SseOHTNv3rxMmTIlO+ywQ0488cRCsx199NE54IAD0rt375Zs9913X2666ab8+Mc/LjTbvffem9GjR2fLLbfMRz7ykcybNy/PPPNMTj755FJ8q+GWW27JQQcdlLFjxy5zW5GnkSnznJY5W7NBgwalsbFxqYt8vtccrylf+9rXcsopp2TnnXduWTZjxoxccMEFmThxYmG5mj3yyCM599xz09TU1PI8rdVqGT58eLp37150vCTJwIED853vfCfbbbddHnvssYwcObLQsSvznMpWnVzNyroPUuZxK3O2xJy2VlnHrVn//v1z6aWX5p/+6Z/y6quvZvDgwbnpppuKjlXqD6RGjhyZpqampfYrJ0+enMWLF+e8884rNFtZC+Iyf/ElKe/ztKy5knK/Zy5ztjLPaZmzlXm7W+Zs7zenO+64Y7797W8Xmq2s41b2/coyb9/KOqdlzlbm+Sxztvvvvz977rlnbrnllmVuK/oyKoWOW41arVar9e/ff5llTU1NtUMOOaSANEsbMGDAey5/r8xrWt++fWtz5sxZatlbb71VO/jggwtK9N6amppqb731Vm3OnDm1W265pfaXv/yl0DxlntMyZ2t22GGHFR1hKX379l2l5Wtav379ai+99NJSy1588cVSbN+a/f2cFj3HZZ5T2VZdWXM1K+s+SJnHrczZajVz2lplHbdmZXutajZw4MDajBkzllr2+9//vhTz+n5jVIZsZR23suZqVtbnaVlz1Wrlfs9c5mxlntMyZyvzdrfM2czpqiv7fmWZt29lndNarbzZyjyfZc7WbN68ebWXX3659uc//7k2duzY2gsvvFB0pELHre3qrdvWHosXL84LL7yw1Hn3X3jhhVKcouKjH/1oxo4dm969e6dTp04tR+xstNFGRUfLokWLss466yy1rKGhofDDaP/e0KFDs8cee+T3v/99mpqa8utf/zpXXHFFYXnKPKdlztasZ8+euf/++7PNNtu0LNt4440Ly/PJT34yZ555Zvbcc8907ty5ZczKcBHv5J3t28c//vGlln384x8v1fO0bdu2ueeee9KzZ8889NBDhR9aXuY5la06uZqVdR+kzONW5myJOW2tso5bs06dOmX8+PH51Kc+lYceeijrrbde0ZGSvHM9yXd/OztJaa411dTUlN/97nfp2bNny7KHHnqoFNdfK+u4lTVXs7I+T8uaKyn3e+YyZyvznJY5W5m3u2XOZk5XXdn3K8u8fSvrnCblzVbm+SxztmannnpqDj744Px//9//l0984hMZPnx4rrnmmkIzFTluTpn4NzNmzMg555yTRYsWpVOnTpk7d27at2+fkSNHFn7O4OYLeU6fPr3l+j/du3dPv379lnngrGmTJk3K+PHj06NHj3Tu3Dlz587N9OnTM3DgwBx66KGFZnu3ww47LD/5yU8ycODAjB8/Pl//+tdz7bXXFpbnveZ01113Tf/+/Quf07/P1qlTp3Tv3r0U2ZqdffbZ+d3vftdy4cy6urpCD8mv1Wq56667lpnPvffeuxQvgGPHjs3vfve77LHHHi07qlOmTEmPHj0KPXXou7344ou58MIL88wzz2SbbbbJ6aefXugFPv9+TpufB2WY0zI/3so6bmUes+T990HOOeecZT4UXZPKPG5lzpasPXNaludos4cffjgjRowo5f54ksyZMyfjxo1rea06+uijS1GKjRgxIo2Njct8INU8dkV6/vnnW05LWKvV0qZNm+ywww4ZOnRo4detK+u4lTVXs7Ju38qaKyn3e+YyZyvznJY527u3u0nSpk2bbL/99qXY7pb5NWFtmdMyjVvZ98fLvH0r65y+V7b6+vpSbEPKPJ9lztbs8MMPb/k8/Lrrrmv5fLxIRY6bQuzvzJ07N/PmzUvHjh3TqVOnouO8p2nTpqW+vn6ptr5Ir7/+eh555JGWD1a6deuWDTfcsOhYS+nTp0++8Y1v5KGHHsqQIUPyzW9+M7feemvRsVpMmTIlvXr1KjrGWuPwww/P9ddfX3SMFn/6059adgzuvffePProo9lpp53Su3fvYoO9y6OPPrrMjuqOO+5YdKwWb775Zh599NHsscceuf7667P//vu3FJ5Fueeee9LQ0JDPfvazLcvuuuuuws8BXfbHWxnHrexj1qxs+yBry7glyc9//vMceOCBRcdYRtnmNCnnc/TvlXHcknc+IHjkkUfyla98JRdffHH69eu31DfJi1L2D6Tebf78+amvry/8SPCkvONW1lx/r/l52qlTp3Ts2LHoOC3Kuv0o83vmMmdLyvtYS8r7eFtblOk1odnaMKdlHLeknPvj796+de7cOf/yL/9Squ1bs7LO6bs1NjYWnq/Mr1dlzpYkffv2zZe+9KW8/vrr+epXv5rTTz89P/vZz4qOVdhztPhjf0uisbGx5cm9wQYb5Nhjj82iRYvS2NhYdLTce++9+fznP5/9998/V1xxRf7jP/4j//mf/5lx48YVHS1JsuGGG+YLX/hC9t9//3zhC18o1RO+2RFHHJE777wzRx99dMaPH1/4hW5vvPHGpf5873vfa/l70ZqfC+/1pyy6du2aGTNmlCbb8OHDkyRXX311Jk6cmPXXXz8//elPM3bs2EJzvVubNm2y995751vf+lbefPPN3HvvvZk/f37RsVqcfPLJmTNnTpJkvfXWy2mnnVZonnPOOSe33XZbbrzxxhx11FEtj7Hrrruu0FxJuR9vZR23Mo9Z8s5RMQcffHCOPPLIzJo1q+XN9/HHH19orjKP25gxY5b6c9lll7X8vQwuueSSJO/s4B9//PH58pe/nH79+uXZZ58tNFdZn6N/r1OnTvmnf/qn0n0Qdfrpp7ecQvpzn/tcvvOd7xSc6B3PPfdc9t5775xxxhn54he/mM6dO2edddYpRXkya9asHHfccRk+fHgeeOCB/Nu//Vu+/OUv55577ik6WmnHray5mr355ps5//zzc8MNN+TNN9/MgQcemH333TczZswoNFdZt7vNyvqeefbs2bnmmmvy8MMPZ88992zJVobX+vvuuy/XXXdd3nzzzZxyyinZZ5990qdPnzz22GNFRyv9462syvyaUOY5Leu4lX1/vFarZcaMGenSpUs+97nP5c4778yYMWPy+uuvFx2ttHOaJP/93/+dvfbaK3vvvXd++ctftiw/4ogjCkxV7terMmdrNnTo0Lzxxhs59thjM23atJxzzjlFR8qsWbMyc+bMfPazn82f/vSnTJgwIT/60Y9aPhtcnVxD7G8++9nPpqGhIeuss05qtVpef/317LPPPqmrq8vdd99daLZx48bl9ttvz2uvvZa+ffvmN7/5Terr69O/f/8cd9xxhWZbXoHTt2/fNZhk+b70pS/lS1/6UpLk29/+dsvyESNGFHLqkbvuuitvvfVW9txzzyTvlFCvvfbaGs/xXvbbb7+88cYbWW+99VKr1VJXV9fy36KfC80eeuih3HvvvS3/Lku2e++9N9ddd13atm2b/v375/DDDy/FKQnHjRuX3/72t5k7d2422mijbL/99llnnXUybNiwjB49uuh4Sd75RtS+++6b5J3H4E033VRonieeeCITJkxIkpYSfdy4cSnTQdVlfLyVfdzKOGZJMmrUqIwePTqLFy/O6aefnlNOOSW9evXKW2+9VXS0JOUct7/85S958skn069fv9RqtTQ0NGSrrbYqNNO7/f73v0/yztyeeeaZ6dGjRx5//PGce+65+dGPflRYrrI/R0855ZT3va0sr1e77757kuRTn/pUmpqaCk7zjuHDh+e6667L1Vdfnf/5n/9J796989Of/jSPPPJI4c/Vs846K0OGDMmLL76YE044IXfeeWcaGhpyxBFHZK+99io0W1nHray5mp1++un58pe/nJdeeinf+ta3cv3116dDhw457bTTCj2DQ1m3u0m53zOffvrp2XvvvbN48eIcfvjhufrqq7PJJpvkwQcfLDRXklx++eW54oorMnz48Hz729/Opz71qTz++OMZMWJE4V8kLfPjbeDAgVm0aNFSy5rfzxd5mYGk3K8JZZ7Tso5b2ffHv/vd72b+/Pl57bXX8pe//CV9+/ZNx44dM2zYsFx55ZWFZivrnCbJlVdemVtuuSW1Wi3f/va3s3Dhwhx00EGFv18o8+tVmbM16969e7p3757kncsKNTv++ONzxRVXFJJp6NCh+fa3v53zzjsv//zP/5yTTjopDz30UE455ZRcffXVq/VnK8T+5sYbb8z3v//9nHzyyfnkJz9ZinNpNmtqakqHDh2y5ZZb5oQTTkjbtu9MW9EboyR55plncs8992T//fcvOkqrFPVtn6uvvjqXXnpplixZkhNOOCHTpk0rxRvcJJkwYUIGDRqUH//4x6W4LsZ7+a//+q+iIyxl9uzZefTRR7PRRhtl7ty5WX/99bNgwYIsXLiw6GhJksmTJ2fixImZN29e9ttvv1x11VVJ3nmzVBbt2rXLb37zm+y888753//938IvXrxkyZKWo4YHDhyYl156Kd/73vcKzdSszI+3so5bmccseefx3/zm8eqrr863vvWtbLTRRoUfDVDmcTv33HMzceLEPPjggxkxYkRuueWWHHTQQUXHWsb8+fPTo0ePJMl2222XxYsXF5qnrM/RZvvuu28uueSSUnxj8b2su+66ufHGG7PLLrvkkUceKd2pu8pYXi9evDi77bZbkndO+/7Rj340SVrez5RBGcetzLnefvvtlu3tgw8+mK233jpJCn/Nala27W5S7vfMjY2NLaXc9ttvn+OOOy7jx48vxWcN7du3zz/90z8leedLCMk7c1omZXy8nXrqqRk2bFiuuOKK1NfXFx1nKWvDa0IZ57Ss41b2/fHHH388N9xwQxobG7Pffvu1XJOo6EI9Ke+cJu+8N11//fWTvPPl6q9//ev5+Mc/XvjrfJlfr8qcbUWK/BJufX19dt9991x55ZX57ne/m+Sd8fvVr3612n+2Uyb+zTbbbJPRo0fnqquuyi9+8YvCn+jvdtBBB+WAAw5IU1NTS4s7ZMiQUlzD48wzz8wWW2yR3r17Z/DgwUv94f3V1dXlpJNOynbbbZcTTjih8FP+vVuXLl1yyimn5NFHHy06yjLOPffcJO98k7Jfv35L/SnSIYcckh/96Ef54x//mJ/85CeZO3du/vVf/zVf+9rXCs3VrKmpKS+99FI6duzYciqIt956q1SPu+9973v5yU9+kkMPPTQ33HBDy1wX5Wtf+1q+8pWvZPbs2Une+cbPggULMn369EJzJeV+vJV13Mo8ZknSsWPHXHfddWlsbMxGG22Uiy++OCeeeGJefPHFQnOVfdz69euXPn365Ljjjsu8efOKjrOUP/3pTzn22GMzd+7c3HnnnVm0aFF+8IMf5CMf+Uihucr6HG229957Z4899sgbb7yR3Xbbbak/ZXDBBRfkqaeeykUXXZSnn346559/ftGRkixbXicpTXm95ZZb5jvf+U6amppywQUXJHmn+C/D6eLKOm5lzdVsvfXWazmy9Nprr02S3HrrrWloaCg0V1m3u0m53zMvWbIkTzzxRJJ3vj1+9NFHt4xj0Xbcccece+656d69e84666z8+te/zrBhw7LNNtsUHa3Uj7edd945BxxwQJ544olssskmS/0pWplfE8o8p2UetzLvjyfJ9OnT0759+5aj/J577rlSfA5S5jndZJNNMmrUqLz99tvp1KlTxo4dm3PPPTfPPPNMobnK/HpV5mwrUmT/0blz59xxxx353Oc+l5///Of561//ml/84hfp0KHD6v/hNZZx+eWX1/bee++iY7RoamqqzZ49e6llzzzzTEFpljV79uzak08+WXSMVhk4cGAhP7epqanl708++WTt+9//fiE53su7s5XNf/3Xf9VqtVrthRdeWOZPkV599dVlls2ZM6eAJO/toYceqh188MG1JUuWtCwbMGBA7e677y4w1coZPnx4IT/31VdfrS1YsGCZ58PMmTMLyfNuZX68lXXcyjxmtdo7WS677LKlMv3xj3+sHXvssQWmKve4vTvbn//859p1111XYJr39txzz9Vuv/322kMPPVSbP39+7aKLLqr99a9/LTRTWZ+ja7vjjjuu0J//ox/9qHbqqafW/vVf/7U2duzY2pw5c2qf+9znarfeemuhuWq1Wm3JkiW1X//610st+/nPf157++23C0r0f8o6bmXN1eztt9+u/fjHP15q2VVXXVV7/fXXC0r0f8q43W1W1vfMjz32WO2AAw6ovfLKKy3Lfv7zn9d22223AlO9Y8mSJbWf/exntZNPPrn2zW9+s3bSSSfVrr/++trChQuLjlar1cr9eCurMr8m1GrlndOyjlvZ98efeuqp2vHHH1+bO3duy7Jjjjmm9vvf/764UH9T1jmt1Wq1RYsW1W6++ealsrz22mu1733vewWmKvfrVZmzrUhRn4vXarXaG2+8UTvuuONq/+///b/ajjvuWNtjjz1qJ5xwQu3FF19c7T9bIfY3V155ZdER3leRD84VGT9+fG2vvfaq7b333rX77ruv6DirrKixLfOcyrbqypqr2dr8Qafn6LJkW3VlzdWsrPsgZR63Mmer1cxpa5V13Fbk8MMPL/Tnl7m87t+/f+3nP/95aT7AfreyjltZczUr6/O0rLlqtXK/Z36/bO/+Il1RyjynZc7Wv3//2q233lrK7W6ZXxPKPqdlHLey71eWedtb1jmt1cqbrcyvV2XOtiJFPo+vv/762l577VX74he/uMafo06Z+De/+c1vio7wvmolPufobbfdljvuuCMTJ07MddddV3Sc9zVnzpz3XF7msWVZtVotixYtSmNj4zJ/eH/Nh+AD5VTmfRBax5y2zto6bkWfav3UU09dZlmnTp0KSLKs4cOH53//93+z33775fzzz8/TTz9ddKQWZR23suZqVtbnaVlzJeV+z3zbbbflzjvvXCZb0dfzTco9p2XONnz48DzyyCOl3O6W+TWh7HNa1nErs/fbvpVBmee0rNnK/HpV5mzNFi1a9J7L11tvvTWc5P/813/9V+68887ceOONa/w5WvzV+kriL3/5S6ZMmfKet/Xq1WsNp1na008/nVNOOeU9bxs9evQaTrO09u3bp3379unSpcv7PrnK4KijjsqECROWWf7DH/6wgDTJU089Vdo5LXO2hx9+OPvuu29LkVlXV5darZa6urrcfffdheWaOXPmMtcxa841ceLEglLxjyjznMq26sqaq1lZ90HKPG5lzpaY09Yq67jRetttt12GDRuWxsbG3H333bnggguyYMGCHHLIITnggAOKjkcrlPV5WtZcSbnfM7dv3z7t2rUrZbYyz2mZs5V5u1vmbOZ01ZV9v7LM27eyzmmZs5V5PsucrdnBBx+cT3/60zn00EPTtWvXluWXX355YZmKHDeF2N/Mnj07t99++3veVvSL38c+9rH07du30Awro8xHW6233nq59tprs9VWW7U09L169Uq7du0KyVPmOS1ztp133jnjx48vOsYyPvGJTxReFi7P//zP/7zvduz9dvo/7Mo8p7KturLmalbWfZAyj1uZsyXmtLXKOm5lV/YPpJJ33vD+67/+a7p3757rr78+5513XuEf+JR13Mqaq1lZn6dlzfX3yvyeuWzZyjynZc7WrIzb3WZlzGZOV13Z9yvfrWzbt2Zlm9N3K3O2ss5nUt5st956a+6///6MHTs2b775Zvbff/98+ctfTseOHYuOlmTNj5tC7G+22mqrjBo1qugY76lz587Zbbfdio7xnpqPJqrVasscWVSmF8YNNtggjz/+eB5//PGWZUXu1JR5Tsucrazat2+fTTbZpOgY72vXXXctZZH4bnPmzEnnzp2XWV7UzkSZ51S2VVfWXM3Kug9S5nErc7bEnLZWWcet2aJFi97zy1RFnmokKf8HUgsWLMgdd9yRX/ziF5kzZ04OOeSQ/Pd//3fRsUo7bmXN1aysz9Oy5krK/Z65zNnKPKdlzpaUd7ublDebOV11Zd+vLPP2LSnnnDYrY7Yyz2eZszVr06ZNevfunST56U9/mvHjx+fmm2/OQQcdVNhBEUWOm0Lsb+rr64uO8L4+//nPFx3hfV166aUtf//7bzKWSdl2bMo8p2XOdvbZZydJ5s2bt9S3GF5++eV8/OMfLypWDjnkkMJ+dlWU7bSmZZ5T2VZdWXM1K+s+SJnHrczZEnPaWmUdt2ZlPNVIUu4PpIYOHZrf/va3+cIXvpDTTjst22+/fdGRWpR13Mqaq1lZn6dlzZWU+z1zmbOVeU7LnK3M290yZzOnq67s+5Vl3r6VdU6T8mYr83yWOVuz73//+7n77ruz22675cgjj0y3bt3S1NSUgw8+uLBCrMhxq6uV9Vg+WizvlGZlOXS77N49Tn/5y1+y2Wab5Ve/+lVheco8p2XO1mz//ffPRRddlE9+8pO58847c+mllxY6nxMnTkxdXd173laG008+8MAD+exnP1t0jOU65phj8pnPfGaZ05oWpcxzKtuqK2uusivzuJU5W5kZt39MU1NT7r///tx8882lOtXIrbfeWppT2Py9vfbaK7vsskvWWWedZW4r+gtrZR23suYC1g5l3u6WOVuZlXXc7Fe2XlnnNCl3Nlpv0qRJ+bd/+7dl3re88MIL2XTTTQtKVRxHiP3N8j54LfoaO+93HuNFixaVpqAou3fP4YsvvpixY8cWmKbcc1rmbM3GjBmT73znO/noRz+atm3b5ic/+UmheV5//fVlls2ePTs33XRTKXYEp06dmt/+9rfvedvJJ5+8htO8t7Kd1rTMcyrbqitrrmZl3Qcp87iVOVtiTlurrOPWrIynGkmS+fPn58Ybb3zP24qe106dOmXmzJnZb7/9suuuu5bqugplHbey5mpW1udpWXPRemWe0zJnK/N2t8zZzOmqK/t+ZZmVdU6Tcmej9Xbbbbdcf/31WbRoUZLkz3/+c84999wPZRmWKMRa9O/fP8cff3yS5NVXX80//dM/FZzo/7xfA1/2w5PLapNNNskzzzxTaIYyz2mZszVrfkFubGxMu3btCj+9weDBg1v+/sgjj+T666/Pb37zm9KM2dZbb110hBUq2zeNyjynsq26suZqVtZ9kDKPW5mzJea0tco6bs3KeKqR5J0PpObMmZP6+vp85CMfKSzHe/mv//qvPPnkk/nFL36Rq6++Op/61Key//77Z4sttig6WmnHray5mpX1eVrWXLRemee0zNnKvN0tczZzuurKvl9ZZmWd07Jno/XOOOOM7LXXXvmf//mffOxjH8vbb79ddKRCKcT+Ztq0aS0vfqeddlquu+66ghOtmJZ+5Z188skth3L/+c9/zkc/+tGCE723Ms9pmbKdeOKJueCCC/Iv//IvueOOOzJgwID3PbJtTWhsbMztt9+en/zkJ2nfvn3mzp2bu++++z0PMS/CQQcdlCeffDIdOnTIZpttVnSc91S205qWeU5lq06uZmXdBynzuJU5W2JOW6us49Zsyy23zM9+9rOlTjXSpk2bws88sP766+dnP/tZ2rZtm2HDhrUcxVYWXbt2zamnnpokeeihhzJ69Oi88sormTRpUqG5yjpuZc3VrKzP07LmovXKPKdlzpaUd7ublDebOV11Zd+vLLsyzmmzMmejddZZZ50cffTR+dOf/pRRo0ZlwIABRUcqlELsb979YX+ZPvhfnvc7Vy/LevfF+RoaGrLTTjsVmOb9lXlOy5TtxhtvTKdOnZIk++67b7p161Zoni984Qv5yle+kosvvjhbbrlljjjiiFLtBF5yySWZNm1aGhsb8/Wvf72U16Uo22lNyzynslUnV7Oy7oOUedzKnC0xp61V1nFrVtZTjdx222258847M2fOnJx++umlK1CSZO7cufn1r3+d2267LfPnz8/+++9fdKTSjltZczUr6/O0rLlovTLPaZmzNSvjdrdZGbOZ01VX9v3KtUHZ5vTdypyNVVer1fLaa69l3rx5efvtt/PXv/616EiFUoj9zbs/7C/TB//J0kc3NavVapk1a1ZBidY+O+ywQ6644oo8/fTT2XLLLbPFFltk/fXXLyxPmee0zNnOPffcDB8+PIMGDWrJWKvVUldXl4kTJxaW62tf+1puu+22vPjiiznkkENKtwM9bdq0TJw4MW+//XYGDx5cykLs3cpwWtMyz6lsq66suZqVdR+kzONW5myJOW2tso5bs7KeaqR9+/Zp165dunTp0lLWlcWvfvWr3H777XnppZfypS99KSNHjiy8QGxW1nEra65mZX2eljUXrVfmOS1ztjJvd8uczZyuurLvV5ZZWec0KXc2Wm/w4MG56667csABB+SLX/xi6T8XXN3qarZYSZIePXpk2223Ta1Wy1NPPdXy96I/aE+SBx988H1v22233dZgkrXXCSeckE996lPp2bNnHnzwwUydOjVXXnllYXnKPKdlzvb6669nww03zIsvvrjMbZtsskkBiZb24IMP5qabbsrkyZNzyCGH5IADDkjXrl2LjpWvfe1rLad8ePffy+TvT2vauXPnjBs3ruBU5Z3TRLYq5SrzPkhS3nFLypvNnLZO2cftG9/4Rn784x/nzDPPbDnVyA033FB0rFK/zm+33XbZeuuts9122yVZ+kPG0aNHFxUrSXnHray5mpX1eVrWXLRemee0zNnKvN0tczZz2npl3a8sszLPaZmzseq+8IUvLHVAQbt27bJo0aI0NDQUepmSoinE/ua9PmBvVoYP2vnHDBw4MOPHj2/5d1k+wKB1Xn755dx2221ZuHBhy7J3X9C1aG+99VZuvfXW3Hzzzfn5z39edJzSf7CSLF3ENp/WtL6+vsBESyvbnL6bbKuubLnWln2Qso3bu5UtmzltnbKP29e//vVcfPHF+e53v5sLLrgghx56aKHXMG322c9+Np/5zGdSq9Xy29/+Np/5zGdabiv6g4syf9GqrONW1lzNyvo8LWsuWq/Mc1rmbGXe7pY5mzn9x5Vtv7LMyjynZc7GqmtsbEytVsvIkSPTr1+/dOvWLY8++mgmTJiQ7373u0XHK4xCjA+FPn365IorrshGG22U1157LUOGDCn8Wz60Xp8+ffKZz3wmH//4x1uWvfs6cSyt+dtuSfLUU0/lE5/4RGm+7dZs7ty5S53W9Ljjjiv0tKYA8PceeuihPPXUU/nYxz6Ws88+OwcccECGDh1adCwfXLRSWcetrLkAAFg7/f2BIocddlh+8pOfFJioWAoxPhQeeOCBDB8+PJ06dcrcuXPz3e9+d6lvW7J2+eY3v5kf/ehHRcdYa7z44ouZM2dOrrnmmrz55pvp2bNn9t1337Rr167wb7s1K9tpTQGgmVONAAAAa6vjjjsuXbt2Tbdu3TJjxoy88sor+f73v190rMK0KToArAkvvPBC2rdvn+eeey5NTU0ZNmxY0ZH4B2y77ba5/fbb88wzz+TZZ5/Ns88+W3SkUnvkkUfyne98J7vttlv69++fjh075oQTTshjjz1WdLQWb775ZgYOHJjtt98+X//61/PWW28VHQkAkiR33HFHfvnLX2b33XfPpZdemjvvvDNjx45Nz549i44GAACwXBdffHE22mijTJ48ORtuuGFGjRpVdKRCtS06AKwJEydOzH/+539mo402KjoKH4DHHnssjz/++FLLynhdrLK47rrrMn78+HzkIx9pWXbQQQfl2GOPzRe/+MUCk/2fhQsX5rXXXms5rWlTU1PRkQAgSdK+ffskyaxZs9KtW7ckyQ477JBnnnmmyFgAAAAr9JGPfCSHHXZY0TFKQyHGh8IGG2xQmlPD8Y/7+wvedu7cuaAka4e2bdsuVYYlSadOnVJfX19QomWdeOKJ6d+//1KnNQWAMuncuXMuvfTSllON2LcEAABYuyjEqLQxY8YkSRobGzNo0KDssMMOLdeAOPnkk4uMxj/gjjvuSPLOdTz+8Ic/5M477yw4Ubk1P+b/XpmOwnr3aU032GCDDBs2LHfffXfRsQCgxcUXX5xbbrklkydPztZbb51vf/vbRUcCAABgFSjEqLStttpqqf9SDc2nLkqSHj16tBSfvLennnoqp5xyylLLarVann766YISLctpTQEoO6caAQAAWLspxKi0gw46qOgIrAajR49uOerptddeS5s2bQpOVG6XXnrpey7v16/fmg2yHE5rCgAAAACsTnW1Wq1WdAiAVXHLLbe0/L2hoSF77rmn64itpZqP7vv973+f9u3bO60pAAAAALBaOEIMWOs48q86nNYUAAAAAFgTHCEGAAAAAABApbnwDgAAAAAAAJWmEAMAAAAAAKDSXEMMAACgYC+88EL23XffbLPNNkstv/LKK/Pxj398pe9n1qxZ+Y//+I+cf/75H3REAACAtZpCDAAAoAQ+9rGP5dZbb/2H7uOll17KrFmzPqBEAAAA1eGUiQAAACX1+uuv57jjjsvBBx+cr371q3nggQeSJK+++moGDRqUPn365POf/3z+/d//PUnyve99L3/4wx8ycuTITJs2LQMHDmy5rzPOOCM/+9nPWo5G69+/f775zW9myZIlGTVqVA466KDsv//++fGPf1zErwoAALBaOUIMAACgBP785z/ngAMOaPn3fvvtl5kzZ+arX/1q/t//+3/585//nAEDBuTnP/95brvttnzlK1/JQQcdlDlz5uRzn/tcBg4cmGHDhmXs2LEZMWJEpk2b9r4/69lnn80PfvCDbLrpppkwYUKS5JZbbkljY2MGDRqUnXbaKT179lztvzMAAMCaohADAAAogfc6ZeLuu++eZ555JpdddlmSZPHixZk1a1YGDRqU3/72t7nmmmvyxz/+MYsWLcr8+fNX+md99KMfzaabbpokmTp1ah577LH89re/TZK8/fbbeeKJJxRiAABApSjEAAAASqqpqSnXXntt1l9//STvHEX20Y9+NBdccEFmzZqVr3zlK/niF7+YBx54ILVaban/t66ubqllixYtavn7Ouus0/L3JUuW5LTTTsuXvvSlJMns2bPTsWPH1fhbAQAArHmuIQYAAFBSn/70p3PDDTckSZ566qnst99+mT9/fn7zm99k0KBB+dd//dc8++yzefXVV9PU1JT6+vosXrw4SbLBBhtk1qxZWbhwYf7yl79k+vTp7/szJk2alEWLFmXevHkZMGBAZsyYsaZ+RQAAgDXCEWIAAAAlNWzYsAwfPjz77bdfkuT73/9+OnXqlKOPPjqnn3561llnnfzzP/9zdtppp7zwwgvZfvvtM2fOnJx22mm56KKL8rnPfS7/9m//lk022SQ9evR4z5/Rr1+/PPfccznooIOyePHiHHzwwdl9993X5K8JAACw2tXV/v68GgAAAAD/fzt3QAIAAAAg6P/rfoTeCAIAgBHLRAAAAAAAANYEMQAAAAAAANYEMQAAAAAAANYEMQAAAAAAANYEMQAAAAAAANYEMQAAAAAAANYEMQAAAAAAANYEMQAAAAAAANYCnu86LldrB4IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 2160x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fast_fi = automl.get_feature_scores('fast')\n",
    "fast_fi.set_index('Feature')['Importance'].plot.bar(figsize = (30, 10), grid = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightautoml.report.report_deco import ReportDeco\n",
    "RD = ReportDeco(output_path = 'tabularAutoML_model_report')\n",
    "\n",
    "automl_rd = RD(\n",
    "    TabularAutoML(\n",
    "        task = task,\n",
    "        timeout = TIMEOUT,\n",
    "        cpu_limit = N_THREADS,\n",
    "        reader_params = {'n_jobs': N_THREADS, 'cv': N_FOLDS, 'random_state': RANDOM_STATE}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:06:26] Stdout logging level is INFO.\n",
      "[10:06:26] Task: binary\n",
      "\n",
      "[10:06:26] Start automl preset with listed constraints:\n",
      "[10:06:26] - time: 900.00 seconds\n",
      "[10:06:26] - CPU: 4 cores\n",
      "[10:06:26] - memory: 16 GB\n",
      "\n",
      "[10:06:26] \u001b[1mTrain data shape: (269951, 59)\u001b[0m\n",
      "\n",
      "[10:06:34] Layer \u001b[1m1\u001b[0m train process start. Time left 892.62 secs\n",
      "[10:06:58] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[10:07:33] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.9999323481178684\u001b[0m\n",
      "[10:07:33] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[10:07:33] Time left 833.79 secs\n",
      "\n",
      "[10:07:51] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[10:08:14] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[10:09:20] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.9999945586635057\u001b[0m\n",
      "[10:09:20] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[10:09:20] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 1.00 secs\n",
      "[10:09:29] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[10:09:29] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[10:10:20] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.9999964559030253\u001b[0m\n",
      "[10:10:20] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[10:10:20] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training has stopped (degenerate solution on iteration 66, probably too small l2-regularization, try to increase it)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:12:40] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.9997940653863284\u001b[0m\n",
      "[10:12:40] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[10:12:40] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 1.00 secs\n",
      "[10:13:27] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[10:13:27] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[10:20:02] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.9999842962171427\u001b[0m\n",
      "[10:20:02] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[10:20:02] Time left 84.38 secs\n",
      "\n",
      "[10:20:02] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[10:20:02] Blending: optimization starts with equal weights and score \u001b[1m0.999977443858639\u001b[0m\n",
      "[10:20:05] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.9999964559030253\u001b[0m, weights = \u001b[1m[0. 0. 1. 0. 0.]\u001b[0m\n",
      "[10:20:08] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.9999964559030253\u001b[0m, weights = \u001b[1m[0. 0. 1. 0. 0.]\u001b[0m\n",
      "[10:20:08] Blending: no score update. Terminated\n",
      "\n",
      "[10:20:08] \u001b[1mAutoml preset training completed in 821.58 seconds\u001b[0m\n",
      "\n",
      "[10:20:08] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) \n",
      "\n",
      "Wall time: 13min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "oof_pred = automl_rd.fit_predict(df_train, roles = roles, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = automl_rd.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9996888335704125"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df_test[TARGET_NAME], (test_pred.data[:,0] > 0.5).astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель показала хороший результат как на тренировочных, так и на тестовых данных,\n",
    "accuracy_score на тесте равен 0.9996888335704125. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
